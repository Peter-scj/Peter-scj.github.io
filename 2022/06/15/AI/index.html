

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="">
  <meta name="keywords" content="">
  
    <meta name="description" content="机器学习 &amp; 深度学习 &amp; 计算机视觉——笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="AI">
<meta property="og:url" content="http://example.com/2022/06/15/AI/index.html">
<meta property="og:site_name" content="Blog-Peter J">
<meta property="og:description" content="机器学习 &amp; 深度学习 &amp; 计算机视觉——笔记">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/AI/image-20220801101315800-16619393822671.png">
<meta property="og:image" content="http://example.com/AI/image-20220801220943545-16619393822682.png">
<meta property="og:image" content="http://example.com/AI/image-20220801100309828-16619393822683.png">
<meta property="og:image" content="http://example.com/AI/image-20220802100736808-16619393822686.png">
<meta property="og:image" content="http://example.com/AI/image-20220802101035423-16619393822684.png">
<meta property="og:image" content="http://example.com/AI/image-20220802114501848-16619393822685.png">
<meta property="og:image" content="http://example.com/AI/image-20220814212914680-16619393822687.png">
<meta property="og:image" content="http://example.com/2022/06/15/AI/AI/image-20220814213145968-16619393822688.png">
<meta property="og:image" content="http://example.com/AI/image-20220814213441012-166193938226812.png">
<meta property="og:image" content="http://example.com/2022/06/15/AI/AI/image-20220814214009626-16619393822689.png">
<meta property="og:image" content="http://example.com/2022/06/15/AI/AI/image-20220814221434188-166193938226810.png">
<meta property="og:image" content="http://example.com/AI/image-20220814221542879-166193938226811.png">
<meta property="og:image" content="http://example.com/AI/image-20220814222110164-166193938226813.png">
<meta property="og:image" content="http://example.com/AI/image-20220814223622659-166193938226814.png">
<meta property="og:image" content="http://example.com/AI/image-20220816142718848-166193938226815.png">
<meta property="og:image" content="http://example.com/AI/image-20220816143518592-166193938226816.png">
<meta property="og:image" content="http://example.com/AI/image-20220816151316682-166193938226817.png">
<meta property="og:image" content="http://example.com/2022/06/15/AI/AI%20%E7%AC%94%E8%AE%B0/image-20220816151819438-166193938226818.png">
<meta property="og:image" content="http://example.com/2022/06/15/AI/AI/image-20220816152416125-166193938226819.png">
<meta property="og:image" content="http://example.com/AI/image-20220816153211078-166193938226920.png">
<meta property="og:image" content="http://example.com/AI/image-20220816154055313-166193938226921.png">
<meta property="og:image" content="http://example.com/AI/image-20220816155741815-166193938226922.png">
<meta property="og:image" content="http://example.com/AI/image-20220816162328358-166193938226923.png">
<meta property="og:image" content="http://example.com/AI/image-20220816162408082-166193938226924.png">
<meta property="og:image" content="http://example.com/AI/image-20220816180534814-166193938226925.png">
<meta property="og:image" content="http://example.com/AI/image-20220816180124692-166193938226926.png">
<meta property="og:image" content="http://example.com/2022/06/15/AI/AI/image-20220816183408504-166193938226927.png">
<meta property="og:image" content="http://example.com/AI/image-20220816203104544-166193938226928.png">
<meta property="og:image" content="http://example.com/AI/image-20220816225155327-166193938226929.png">
<meta property="og:image" content="http://example.com/AI/image-20220816225635333-166193938226931.png">
<meta property="og:image" content="http://example.com/AI/image-20220816230116416-166193938227057.png">
<meta property="og:image" content="http://example.com/AI/image-20220816222244332-166193938226930.png">
<meta property="og:image" content="http://example.com/2022/06/15/AI/AI/image-20220816223109918-166193938226932.png">
<meta property="og:image" content="http://example.com/AI/image-20220816224755396-166193938226933.png">
<meta property="og:image" content="http://example.com/AI/image-20220817150143427-166193938226938.png">
<meta property="og:image" content="http://example.com/AI/image-20220817150414893-166193938226934.png">
<meta property="og:image" content="http://example.com/AI/image-20220817151306431-166193938226935.png">
<meta property="og:image" content="http://example.com/AI/image-20220817152255001-166193938226936.png">
<meta property="og:image" content="http://example.com/AI/image-20220817153354437.png">
<meta property="og:image" content="http://example.com/AI/image-20220817154401670.png">
<meta property="og:image" content="http://example.com/AI/image-20220817160917555-166193938226940.png">
<meta property="og:image" content="http://example.com/AI/image-20220817165407108.png">
<meta property="og:image" content="http://example.com/AI/image-20220825094512491.png">
<meta property="og:image" content="http://example.com/AI/image-20220825094618162.png">
<meta property="og:image" content="http://example.com/AI/image-20220817170412882.png">
<meta property="og:image" content="http://example.com/AI/image-20220817171226025.png">
<meta property="og:image" content="http://example.com/AI/image-20220817172716638.png">
<meta property="og:image" content="http://example.com/AI/image-20220817172729730.png">
<meta property="og:image" content="http://example.com/AI/image-20220825100111084.png">
<meta property="og:image" content="http://example.com/AI/image-20220825100037369.png">
<meta property="og:image" content="http://example.com/AI/image-20220825100912849.png">
<meta property="og:image" content="http://example.com/AI/image-20220825101855984.png">
<meta property="og:image" content="http://example.com/AI/image-20220825102935325.png">
<meta property="og:image" content="http://example.com/AI/image-20220825103639197.png">
<meta property="og:image" content="http://example.com/AI/image-20220825105424279.png">
<meta property="og:image" content="http://example.com/AI/image-20220825110943060.png">
<meta property="og:image" content="http://example.com/AI/image-20220825114743843.png">
<meta property="og:image" content="http://example.com/AI/image-20220818152444583-1661939503311115.png">
<meta property="og:image" content="http://example.com/AI/image-20220818153921778-1661939503311116.png">
<meta property="og:image" content="http://example.com/AI/image-20220818155336123-1661939503311117.png">
<meta property="og:image" content="http://example.com/2022/06/15/AI/AI/image-20220818155245104-1661939503311118.png">
<meta property="og:image" content="http://example.com/AI/image-20220818155359103-1661939503311119.png">
<meta property="og:image" content="http://example.com/AI/image-20220818155412509-1661939503311120.png">
<meta property="og:image" content="http://example.com/AI/image-20220818155421399-1661939503311121.png">
<meta property="og:image" content="http://example.com/AI/image-20220818170040695-1661939503311122.png">
<meta property="og:image" content="http://example.com/AI/image-20220818171819211-1661939503311123.png">
<meta property="og:image" content="http://example.com/AI/image-20220818172442170-1661939503311124.png">
<meta property="og:image" content="http://example.com/AI/image-20220819225125424-1661939503311127.png">
<meta property="og:image" content="http://example.com/AI/image-20220819233744661-1661939503311125.png">
<meta property="og:image" content="http://example.com/AI/image-20220819234009147-1661939503311126.png">
<meta property="og:image" content="http://example.com/AI/image-20220819234126710-1661939503311128.png">
<meta property="og:image" content="http://example.com/2022/06/15/AI/AI/image-20220828112522500-1661939559664143.png">
<meta property="og:image" content="http://example.com/2022/06/15/AI/AI/image-20220828112806636-1661939559664144.png">
<meta property="og:image" content="http://example.com/AI/image-20220828130610498-1661939559664145.png">
<meta property="og:image" content="http://example.com/AI/image-20220828113641777-1661939559664146.png">
<meta property="og:image" content="http://example.com/AI/image-20220828132927367-1661939559664147.png">
<meta property="og:image" content="http://example.com/AI/image-20220828135503321-1661939559664148.png">
<meta property="og:image" content="http://example.com/AI/image-20220828135715221-1661939559664149.png">
<meta property="og:image" content="http://example.com/AI/image-20220828141452704-1661939559664150.png">
<meta property="article:published_time" content="2022-06-15T01:21:15.000Z">
<meta property="article:modified_time" content="2024-06-04T13:36:36.571Z">
<meta property="article:tag" content="学习笔记">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/AI/image-20220801101315800-16619393822671.png">
  
  
  
  <title>AI - Blog-Peter J</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"left","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":1},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>PeterJ</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/bg.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="AI"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-06-15 09:21" pubdate>
          2022年6月15日 上午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          12k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          98 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="padding-left: 2rem; margin-right: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">AI</h1>
            
            
              <div class="markdown-body">
                
                <p>特此说明：该笔记仅用于学习用途，不用作任何商业用途！</p>
<h1 id="Machine-Learning"><a href="#Machine-Learning" class="headerlink" title="Machine Learning"></a>Machine Learning</h1><h2 id="机器学习概念"><a href="#机器学习概念" class="headerlink" title="机器学习概念"></a>机器学习概念</h2><ul>
<li><p>training set：训练集。用于训练机器学习算法的模型。</p>
</li>
<li><p>x：input varible。输入变量，也称为输入特征。</p>
</li>
<li><p>y：output varible。输出变量。</p>
</li>
<li><p>m：训练集样本个数。</p>
</li>
<li><p>n：输入的特征属性个数。（对于一个输入样本具有的feature数）</p>
</li>
<li><p>($ x^(i) $, $ y^(i) $)：表示第 i 个训练样本。。注意 i 表示索引而不是求幂运算。</p>
</li>
<li><p>$ \hat{y} $：yhat，估计值，输入到模型得到的输出。区别于 $ y $ ：真实值，指训练集样本的真实输出。</p>
</li>
<li><p>generalization：泛化能力。指的是模型适应新数据的能力。</p>
</li>
</ul>
<br>

<h2 id="Learning-algorithms（学习算法）"><a href="#Learning-algorithms（学习算法）" class="headerlink" title="Learning algorithms（学习算法）"></a>Learning algorithms（学习算法）</h2><ul>
<li><p>Supervised learning（监督学习）——现如今社会和工业界最常用（99%？）。</p>
<ul>
<li><p>definition: learns from being given “right answers”</p>
</li>
<li><p>监督学习的本质：找出输入 x 到输出 y 的最佳映射关系。</p>
</li>
<li><p>监督学习应用：</p>
<p><img src="/AI/image-20220801101315800-16619393822671.png" srcset="/img/loading.gif" lazyload alt="监督学习举例"></p>
</li>
<li><p>使用监督学习算法的两类常见问题：<strong>回归</strong>问题（<strong>regression</strong>）和<strong>分类</strong>问题（<strong>classification</strong>）。</p>
<ul>
<li>回归问题：给定有限的数据集（离散点），通过监督学习算法，得到拟合这些离散数据点的最佳函数，即得到了一条最佳拟合曲线，从而实现对其他非数据集中的数据进行估计和预测。总结的说：回归问题是将输入经过回归模型最终预测为一个特定的值作为输出，而回归算法的目的就是为了获取一个最优的回归模型</li>
<li>分类问题：predict categories(class)。</li>
</ul>
<p>回归问题和分类问题的区别在于：回归问题要解决的是一段<strong>连续区间上任意点的预测</strong>，换句话说<strong>回归问题的输出的范围为一个无限的集合（数的区间）</strong>，而分类问题是对<strong>离散结果的预测，区分不同的类别</strong>，<strong>输出结果的范围是一个由有限多种可能组成的集合</strong>，例如区分猫狗兔，判断是否得病，是否为垃圾邮件等确定的离散结果。</p>
</li>
</ul>
</li>
<li><p>Unsupervised learning（无监督学习）</p>
<p><img src="/AI/image-20220801220943545-16619393822682.png" srcset="/img/loading.gif" lazyload alt="监督学习和无监督学习的比较"></p>
<p>​													图：监督学习和无监督学习的比较</p>
</li>
</ul>
<p>分析：如上图所示，左边为监督学习分类算法，对于输出结果都打上了对应的标签（如图中的⭕和×），即所谓的“right answers”，监督学习分类算法的目的是根据已有数据集输入特征（可以有多个输入，对应多个特征，例如上图中有两个输入：age和 tumor size）和对应输出（right answer），找出最佳分类曲线，从而实现对新样本的分类预测。右边为无监督学习示意图，可见输出没有标签，没有对输出划定明确的分类结果，无监督学习的目的是让算法自动的去寻找数据间的结构和关系，主动发现数据间一些有意思的相互联系。例如上面的聚类算法（clustering）发现上面的样本数据可以分为两大类。聚类算法有意思的应用：在众多新闻中聚类找出某个关键词或者某个相关话题提到的相关文章，或者将一些庞杂无体系的大量数据进行筛选、分组管理。聚类算法是自主的判断并将数据划分为不同的聚类，而不需要我们人为提供关键词或者具体的分类标准和结果。</p>
<p>监督学习和非监督学习的对比总结：</p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">监督学习</th>
<th align="center">无监督学习</th>
</tr>
</thead>
<tbody><tr>
<td align="center">输入</td>
<td align="center">可以有多个输入特征</td>
<td align="center">可以有多个输入特征</td>
</tr>
<tr>
<td align="center">输出</td>
<td align="center">有输出，输出有label，即有所谓的 right answers。</td>
<td align="center">没有明确的输出，通过算法自主确定输出。</td>
</tr>
<tr>
<td align="center">作用</td>
<td align="center">对不是数据集中的新的数据进行分类或输出预测</td>
<td align="center">将数据分组成不同的类别（聚类），区别于监督学习，这些类别是我们事先并不知道的。</td>
</tr>
<tr>
<td align="center">代表算法</td>
<td align="center">回归算法，分类算法</td>
<td align="center">聚类算法，异常检测算法，降维压缩算法</td>
</tr>
<tr>
<td align="center">场景</td>
<td align="center">患者是否患癌症的预测，邮件是否为垃圾邮件。</td>
<td align="center">Google新闻等媒体通过你的浏览喜好聚类所有你可能感兴趣的其他内容呈现在你眼前。</td>
</tr>
</tbody></table>
<ul>
<li>Reinforcement learning（强化学习）</li>
</ul>
<p><img src="/AI/image-20220801100309828-16619393822683.png" srcset="/img/loading.gif" lazyload alt="image-20220801100309828"></p>
<p>当Andrew拿出锤子的那刻属实是蚌埠住了，哈哈哈哈</p>
<h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p>$f_{w,b} &#x3D; wx + b$  该公式也常简写为：$f &#x3D; wx + b$ </p>
<p>其中：w，b称为模型参数（parameters），有时也称为系数（coefficients）或者权重（weights）</p>
<h2 id="损失函数（loss-function）"><a href="#损失函数（loss-function）" class="headerlink" title="损失函数（loss function）"></a>损失函数（loss function）</h2><p><img src="/AI/image-20220802100736808-16619393822686.png" srcset="/img/loading.gif" lazyload alt="image-20220802100736808"></p>
<p>说明：</p>
<ol>
<li><p><strong>损失函数的自变量是模型参数</strong>，而不是训练样本。</p>
</li>
<li><p>平方误差损失函数：在线性回归问题中用的最多。</p>
</li>
<li><p>本质上是求模型估计值和实际样本输出值之间的误差，来评价模型的好坏，而改善模型的方向就是使得损失函数的值越小越好。即估计和真值之间误差越小越好。</p>
</li>
<li><p>误差平方的目的是防止正负误差抵消从而使得误差减小；</p>
<p>除以 m 的目的是为了求误差的平均，防止由于样本量的不断增加导致误差不断增大。</p>
<p>除以 2 的目的是为了后面求改损失函数的导数时方便与平方消掉，不影响作为误差的衡量。</p>
</li>
</ol>
<p><img src="/AI/image-20220802101035423-16619393822684.png" srcset="/img/loading.gif" lazyload alt="image-20220802101035423"></p>
<p>线性回归问题的思路：</p>
<p>目的是为了得到一个模型。模型本身具有可调整的模型参数，我们首先确定评价模型好坏的损失函数，然后以使得损失函数最小为目标不断调整模型参数从而得到最优模型。 </p>
<h2 id="梯度下降算法（Gradient-Descent）"><a href="#梯度下降算法（Gradient-Descent）" class="headerlink" title="梯度下降算法（Gradient Descent）"></a>梯度下降算法（Gradient Descent）</h2><p>脑子中通过人最快下山情景来理解梯度下降算法。</p>
<ol>
<li><p>梯度下降算法的目标是自动的不断调整模型参数使得损失函数<strong>最快</strong>达到最小（局部最小，和初始值设置有关）。</p>
</li>
<li><p>梯度下降算法不仅对线性回归有效，同样的也可用于其他各种带有多参数的损失函数，例如 $J(w1,w2,w3,…,wn,b)$</p>
</li>
<li><p>线性回归问题的损失函数为一个U型或者碗状图，而对于其他更为复杂的损失函数可能存在多个局部极小值点，这时候对梯度下降算法给予不同的模型参数初始值，可能会最终收敛到不同的极小值点处。这点需要注意！</p>
</li>
</ol>
<p>梯度下降算法数学表达式</p>
<p><img src="/AI/image-20220802114501848-16619393822685.png" srcset="/img/loading.gif" lazyload alt="梯度下降算法"></p>
<p>说明：</p>
<ol>
<li><p>Alpha：学习率（learning rate），一般位于区间 (0, 1)，学习率总是正数，例如 0.001。可以理解为下山的步子大小。</p>
<p>问：如何正确选择适当的学习率？</p>
<p>答：如果学习率太小，那么梯度下降至接近 loss function 最小值的速度会很慢。</p>
<p>​	   如果学习率过大，梯度下降在接近 loss function 最小值点处会过冲（overshoot），无法收敛至最小值点，甚至会发散。</p>
</li>
<li><p>梯度下降算法就是循环运行梯度下降表达式（即例如上图中左上角的两个公式），对w, b 不断进行更新，从而最快的获得最佳模型参数。 </p>
<p>注意上图下方两种参数更新方式，<strong>正确的是位于左边的所有模型参数同时更新。</strong>注意观察左右两边的 tmp_b 更新的结果是不同的，右边由于先更新了 w，而后将新计算出来的 w 值代入计算 b 的更新，从而没有达到参数同时更新的效果。</p>
</li>
<li><p>在越接近局部最小值的过程中，偏导数将变得越小，即梯度越小（斜率越小），而此时对于固定学习率而言，整个梯度下降算法在逐渐接近局部最小值的过程中下降的幅度也会变得越来越慢。这也比较符合我们的直觉，在接近目标的时候变得细致谨慎一些（梯度小，斜率小，到达最小值时的导数为0，即斜率为0），而远离目标的时候需要幅度大一些（梯度大，斜率大）。</p>
<p>这里想要说明的是<strong>即使保证学习率不变</strong>，导数部分也会根据当前距离损失函数局部最小值的远近进行动态调整，可以实现最终到达极小值点的目标。</p>
</li>
<li><p>如果某个参数初始值恰巧使得loss function（J）到达局部最小值（极小值），那么梯度下降算法不会再让这个参数发生改变。改变学习率也无济于事。</p>
</li>
</ol>
<p>凸函数：只会存在一个最小值，不会存在多个极小值点，该最小值也就是全局最小值点。</p>
<p>对于线性回归问题，一般选用平方误差函数作为loss function，他的图像是一个碗状，是凸函数，只存在一个最小值，也就是全局最小值。</p>
<p>处理线性回归问题采用的是 batch gradient</p>
<p>特征缩放可以加速梯度下降至收敛的速度。</p>
<p>梯度下降的目的是找出使得loss function J最小的w和b的值。</p>
<p>通过看学习曲线learning curve 来判断梯度下降是否收敛。如果曲线渐趋平缓，那么代表收敛。如果曲线先降后升，代表模型发散，或者为学习率太大，或者代码出错等情况。</p>
<p>学习曲线：横坐标为迭代次数，表示运行完几次同步更新模型参数的梯度下降算法；纵坐标为loss function J的值（例如平方误差）。</p>
<h2 id="监督学习——分类问题-classcification"><a href="#监督学习——分类问题-classcification" class="headerlink" title="监督学习——分类问题(classcification)"></a>监督学习——分类问题(classcification)</h2><p>引言：在监督学习中，有两类问题：1. 回归问题(线性回归，多元线性回归)；2. 分类问题。</p>
<p>而本小节讨论的是如何解决分类问题。分类问题区别于回归问题在于其输出结果<strong>有限</strong>，<strong>离散</strong>。</p>
<h3 id="Logistic-Regression-逻辑回归"><a href="#Logistic-Regression-逻辑回归" class="headerlink" title="Logistic Regression(逻辑回归)"></a>Logistic Regression(逻辑回归)</h3><p>逻辑回归算法虽然带有回归两个字，但是逻辑回归是一种解决分类问题的算法，并不是解决回归问题。</p>
<p><img src="/AI/image-20220814212914680-16619393822687.png" srcset="/img/loading.gif" lazyload alt="逻辑回归"></p>
<p>如上图所示，首先对于以上二分类问题是属于分类问题，逻辑回归算法处理。</p>
<p>逻辑回归本质上是由已有的数据集，拟合一条如上图红色部分的曲线，而不是线性回归中的直线拟合。</p>
<img src="AI/image-20220814213145968-16619393822688.png" srcset="/img/loading.gif" lazyload alt="image-20220814213145968" style="zoom:80%;" />

<p>对于拟合曲线一般采用sigmoid函数，也称为logistic函数。</p>
<p>sigmoid函数特点：如上图中的g(z)所示，函数范围为(0，1)，当 z &#x3D; 0 时，g（z）&#x3D; 0.5。</p>
<p><img src="/AI/image-20220814213441012-166193938226812.png" srcset="/img/loading.gif" lazyload alt="logistic 算法"></p>
<p>上图展示的是对于先前提出的肿瘤二分类问题的logistic算法具体实现原理。本质上就是将sigmoid函数的自变量z替换成输入特征即可。</p>
<p>对于输出是介于(0,1)区间的小数，<strong>这里对计算输出的结果正确的理解是：判断结果为 0 或 1 的概率。</strong></p>
<h3 id="逻辑回归算法核心公式"><a href="#逻辑回归算法核心公式" class="headerlink" title="逻辑回归算法核心公式"></a>逻辑回归算法核心公式</h3><img src="AI/image-20220814214009626-16619393822689.png" srcset="/img/loading.gif" lazyload alt="image-20220814214009626" style="zoom:80%;" />



<h3 id="二分类问题的-loss-function"><a href="#二分类问题的-loss-function" class="headerlink" title="二分类问题的 loss function"></a>二分类问题的 loss function</h3><p>（不能再用线性回归中的平方误差函数作为分类问题的损失函数(J)，应当进行改写）</p>
<p>之所以要改的原因是因为如果接着使用平方误差函数做为分类问题的loss function的话，那么他的曲线为此起彼伏的曲线，拥有很多个极小值点，那么就不方便使用梯度下降算法求最优的模型参数。</p>
<img src="AI/image-20220814221434188-166193938226810.png" srcset="/img/loading.gif" lazyload alt="image-20220814221434188" style="zoom:80%;" />

<p>如上图所示为二分类问题中单个输入的 loss function，进一步进行整合简化如下：</p>
<p><img src="/AI/image-20220814221542879-166193938226811.png" srcset="/img/loading.gif" lazyload alt="image-20220814221542879"></p>
<p>综上所述：二分类问题的logistic算法的loss function（J(w,b)）为：（在上面的基础上再求个平均）</p>
<p><img src="/AI/image-20220814222110164-166193938226813.png" srcset="/img/loading.gif" lazyload alt="image-20220814222110164"></p>
<p>逻辑回归算法中的梯度下降算法：</p>
<p><img src="/AI/image-20220814223622659-166193938226814.png" srcset="/img/loading.gif" lazyload alt="image-20220814223622659"></p>
<p>注意：</p>
<ol>
<li>逻辑回归和之前的线性回归问题的梯度下降算法的<strong>偏导部分</strong>形式一样，但是要注意虽然形式一样，但是函数定义不一样，一个是线性函数，一个是sigmoid函数。</li>
<li>对于同一样本的不同取值范围的特征，可以采用特征缩放的手段使得各个特征均处于相同或者类似区间范围内，这样的<strong>特征缩放做法可以加快梯度下降算法的收敛</strong>。</li>
</ol>
<h3 id="过拟合问题-overfitting"><a href="#过拟合问题-overfitting" class="headerlink" title="过拟合问题(overfitting)"></a>过拟合问题(overfitting)</h3><p>采用正则化方法可以最大程度的减少过拟合问题。</p>
<p>回归问题的拟合问题</p>
<p><img src="/AI/image-20220816142718848-166193938226815.png" srcset="/img/loading.gif" lazyload alt="image-20220816142718848"></p>
<p>分类问题的决策边界选择问题</p>
<p><img src="/AI/image-20220816143518592-166193938226816.png" srcset="/img/loading.gif" lazyload alt="image-20220816143518592"></p>
<p>分析（综合上面两张图）：</p>
<ol>
<li>最左边图欠拟合（也称为：high bias），拟合效果不佳；</li>
<li>最右边图为用更高阶的多项式进行拟合出现过拟合现象，虽然拟合曲线很好的匹配了输入测试集样本，但是可以看到该曲线没有很好的泛化能力，并不能很好的描述样本的趋势，若换一个样本集，那么其适应能力大大降低。也称为 high variance。</li>
<li>中间图认为模型 just right，具有很好的泛化能力（generalization）。</li>
</ol>
<p>解决过拟合问题的方法：</p>
<ul>
<li><p>方法1：增加更多的训练集样本用于模型训练。</p>
</li>
<li><p>方法2：对所有样本进行适当的特征选择，而不是利用每个样本所有的特征进行训练，选择最能影响当前输出的几个关键的特征进行模型训练。</p>
<blockquote>
<p>往往模型参数越多，越容易导致过拟合。所以这种方式的思路就是通过减少特征，进而减少模型参数 w1, w2, …，达到防止过拟合的目的。</p>
</blockquote>
</li>
<li><p>方法3：<strong>正则化方法（Regularization）。推荐</strong>，做常用的方式。相对于方法2而言，它并不是对特征进行筛选，而是通过控制调整 w1, w2, …, wn 的值来降低不必要特征对模型的影响。</p>
<blockquote>
<p>当然，一般只会选择减小模型参数 w 的影响而不会选择动 b 参数，理论上正则化 b 对模型整体效果不会由很大的影响，所以一般只会正则化 w。</p>
</blockquote>
</li>
</ul>
<h3 id="正则化（Regularization）"><a href="#正则化（Regularization）" class="headerlink" title="正则化（Regularization）"></a>正则化（Regularization）</h3><p>目的：解决模型过拟合问题</p>
<p><img src="/AI/image-20220816151316682-166193938226817.png" srcset="/img/loading.gif" lazyload alt="image-20220816151316682"></p>
<p>说明：</p>
<ol>
<li><p>以上 J(w, b) 损失函数的表达式是在解决回归问题的平方误差函数的基础上增加了一个正则化项 （regularization term）。</p>
<blockquote>
<ul>
<li>除以 2m 是为了使得无论增加多少样本，lamda依然能够起到相同的正则化作用。</li>
<li>取平方是防止 w 之间正负抵消，这和平方误差的思想类似。</li>
<li>多除以了一个 2 是为了求导的时候抵消平方下来的 2。</li>
</ul>
</blockquote>
</li>
<li><p>lamda 的确定问题。</p>
<p>考虑两种极端情况：</p>
<ul>
<li><p>若 lamda 太小，这里直接将其设置为 0，那么此时相当于正则化项不起作用，原来的高阶函数拟合样本出现过拟合现象。如下图所示。</p>
<img src="AI 笔记/image-20220816151819438-166193938226818.png" srcset="/img/loading.gif" lazyload alt="image-20220816151819438" style="zoom:50%;" />
</li>
<li><p>若 lamda 太大，这里认为它趋于无穷，那么此时正则化项在损失函数中起到很大权重，认为损失函数约等于正则化项，采用梯度下降算法更新模型参数使得损失函数趋于局部最小，即：使得正则化项最小，因为 lamda 很大，那么就会导致所有模型参数 w1, w2,… 变得非常小才可能使得 loss function 最小，这里取极端情况：所有的 w1, w2, …等于0，那么此时 $f_{w, b} &#x3D; b$，为一条平行于x轴的直线，于是此时变成欠拟合（high bais）。如下图所示。</p>
<img src="AI/image-20220816152416125-166193938226819.png" srcset="/img/loading.gif" lazyload alt="image-20220816152416125" style="zoom:50%;" /></li>
</ul>
</li>
</ol>
<p>加入正则化项后的梯度下降算法：（正则化<strong>线性回归问题</strong>，防止过拟合）</p>
<p><img src="/AI/image-20220816153211078-166193938226920.png" srcset="/img/loading.gif" lazyload alt="image-20220816153211078"></p>
<p>说明：</p>
<ol>
<li>加入正则化项只是对 wj 的更新表达式多了一项，而 b 的更新表达式不变。</li>
</ol>
<p>换个角度深入理解增加正则化项的目的</p>
<p><img src="/AI/image-20220816154055313-166193938226921.png" srcset="/img/loading.gif" lazyload alt="image-20220816154055313"></p>
<p>分析：对于上图梯度下降算法中不断更新 wj  和 b，因为加入正则化项对 b 的梯度下降表达式不受影响，这里讨论 wj，如图可以看到这里对 wj 的表达式进行改写得到最下面的手写表达式 wj。可以看到表达式的后半部分和不加入正则化项的梯度下降表达式一样，*<em>只是前半部分由原来的 wj 变为了 wj(1-a</em>lamda&#x2F;m)**。</p>
<p>​		最右边对a，lamda，m 进行了假设赋值，可以看到这样的赋值使得 wj 在每次执行梯度下降算法的时候都将自己乘以一个小于1的数进行了缩小，于是这里就可以看出<strong>正则化的根本目的就是实现对模型参数 wj 的缩小，减小各个模型参数对模型的过分影响，从而防止过拟合。</strong></p>
<p>逻辑回归问题（分类问题）的正则化梯度下降算法</p>
<p><img src="/AI/image-20220816155741815-166193938226922.png" srcset="/img/loading.gif" lazyload alt="image-20220816155741815"></p>
<p>分析：可以看出来逻辑回归问题的梯度下降算法表达式和线性回归问题的形式上是相同的，只是注意 $f_{w,b}$ 的定义不同。线性回归问题是线性多项式，而逻辑回归问题（分类问题）是 sigmoid 函数。</p>
<h2 id="神经网络（neural-networks、deep-learning）"><a href="#神经网络（neural-networks、deep-learning）" class="headerlink" title="神经网络（neural networks、deep learning）"></a>神经网络（neural networks、deep learning）</h2><p>本章学习内容</p>
<ol>
<li>神经网络：推理（Inference，Prediction） &amp; 如何训练</li>
<li>Practical advice for building machine learning systems</li>
<li>Decision Trees（决策树）</li>
</ol>
<p><strong>&#x3D;&#x3D;创建神经网络的思路&#x3D;&#x3D;<strong>：将原来传统的解决</strong>逻辑回归问题</strong>的算法封装在一个个的神经元里，然后将它们连接起来。</p>
<p>神经网络</p>
<p><img src="/AI/image-20220816162328358-166193938226923.png" srcset="/img/loading.gif" lazyload alt="image-20220816162328358"></p>
<p>为什么神经网络（深度学习）现在很火，或者说它与其他传统的机器学习算法的优势在哪里？</p>
<p><img src="/AI/image-20220816162408082-166193938226924.png" srcset="/img/loading.gif" lazyload alt="image-20220816162408082"></p>
<p>分析：通过上面这张图可以看出来用神经网络对样本进行训练的表现（表现指的是训练误差等等评判模型性能的参数）要比传统的机器学习算法（例如线性回归算法和逻辑回归算法）要好很多，而且随着数据量的增加其性能变得更加优异。同时，随着神经网络的规模增大，它的训练效果也会变得更加优秀。</p>
<p>神经网络结构</p>
<p><img src="/AI/image-20220816180534814-166193938226925.png" srcset="/img/loading.gif" lazyload alt="image-20220816180534814"></p>
<p>理解：</p>
<ol>
<li>每一个神经元都是一个 logistic function，输出一个 (0, 1) 区间的小数，可以理解为概率。</li>
<li><strong>每一个神经元都会计算出一个结果</strong>。每一层有多少个神经元，就会输出多少个这样的值，以向量 a 的形式存储起来传递给下一层。</li>
<li>神经网络分为<strong>输入层，隐藏层和输出层</strong>。有时也认为输入层不算神经网络的层级。</li>
<li>上图神经元之间采用全连接的方式连接前后层级。</li>
<li>上标表示所在层级，下标表示属于该层级的神经元标号。具体上下标说明见下图所示。</li>
</ol>
<p><img src="/AI/image-20220816180124692-166193938226926.png" srcset="/img/loading.gif" lazyload alt="上下标定义总结"></p>
<p>​	注意：我们也时常称神经元中的算法函数 sigmoid 或者其他函数为<strong>激活函数</strong>（activation function）。</p>
<p>​				当然激活函数不只有 sigmoid 函数。</p>
<ol start="6">
<li><p><strong>从左到右</strong>的顺序不断激活每个神经元进行计算称为<strong>前向传播</strong>（forward propagation）。</p>
<p><strong>从右向左</strong>进行模型参数学习的过程称为<strong>反向传播算法</strong>（back propagation）。</p>
</li>
<li><p>注意一个细节，一般的神经网络架构在<strong>接近输出层的时候神经元个数在逐渐减少</strong>。</p>
</li>
</ol>
<p>Tensorflow 中的数据存储形式：</p>
<img src="AI/image-20220816183408504-166193938226927.png" srcset="/img/loading.gif" lazyload alt="image-20220816183408504" style="zoom: 50%;" />

<p>分析：</p>
<ol>
<li>Tensorflow 中调用 python 中的 numpy 库生成矩阵（行向量，列向量，多维向量）来存储数据。</li>
<li>注意 Tensorflow 和 numpy 矩阵存储数据的方式不太一样，但是中间可以相互转换。</li>
<li>注意：如上图所示，<strong>在 Tensorflow 中使用前两者方式存储数据</strong>，即：使用<strong>两个中括号</strong>来表示将数据存储在一个二维矩阵中；而最下面这种方式并不表示将数据存储在矩阵中，而是以一个列表一维的形式存储数据。</li>
</ol>
<p>约定俗成：算法中使用到的大写字母认为是矩阵，而小写字母为向量或者标量。</p>
<p>AGI：artificial general intelligence（通用人工智能）</p>
<p><img src="/AI/image-20220816203104544-166193938226928.png" srcset="/img/loading.gif" lazyload alt="image-20220816203104544"></p>
<p>该图的理解：不要因为在 ANI（狭义人工智能）上的成就加上媒体在这方面的炒作就认为目前的 AI 已经很成熟，实际上，在我们目前看得到的 ANI 的应用只是属于 AI 的一个子类，对于通向完全智能的 AGI 仍然还有很长的路要走。</p>
<p><strong>基于Tensorflow搭建一个神经网络模型</strong></p>
<p><img src="/AI/image-20220816225155327-166193938226929.png" srcset="/img/loading.gif" lazyload alt="搭建一个神经网络模型"></p>
<p>名词解释：Sequential：连续排列，activation：激活函数。Dence：该函数表示构建一层神经网络。units：神经元个数。</p>
<p><strong>单个网络层上的前向传播</strong></p>
<p><img src="/AI/image-20220816225635333-166193938226931.png" srcset="/img/loading.gif" lazyload alt="image-20220816225635333"></p>
<p>注意：变量下标表示该层级对应的参数序号，上标表示对应的神经网络层级。</p>
<p><strong>单个网络层上的前向传播的具体底层python代码的实现</strong></p>
<p><img src="/AI/image-20220816230116416-166193938227057.png" srcset="/img/loading.gif" lazyload alt="image-20220816230116416"></p>
<p>说明：</p>
<ol>
<li>注意该实现中的多项式乘法运算没有采用矩阵乘法运算，是利用for循环逐一计算各值，因此该算法的执行效率是很低的，只是帮助原理层面的理解，实际开发代码中不会采用这种方式。</li>
<li>简单了解一下这个机制就好，不需要重点掌握！只是为了方便我们对底层计算的理解。具体的还是应当掌握下面会提到的利用矩阵的乘法运算来进行前向传播（模型推理）。</li>
</ol>
<h3 id="矩阵乘法的理解"><a href="#矩阵乘法的理解" class="headerlink" title="矩阵乘法的理解"></a>矩阵乘法的理解</h3><p>因为像 GPU 和部分 CPU 拥有强大的矩阵乘法计算能力，而利用矩阵乘法计算的运行速度远远快于用普通for循环进行多项式计算的算法，这才使得深度学习得以迅速的发展。</p>
<p><img src="/AI/image-20220816222244332-166193938226930.png" srcset="/img/loading.gif" lazyload alt="image-20220816222244332"></p>
<p>上图说明：两个列向量点乘（图的左边）等价于其中一个列向量的转置（即变为行向量）与另一个列向量的矩阵乘法运算。</p>
<p>注意：至少在深度学习中，鼓励对矩阵的理解为矩阵是由多个有含义的列向量构成的。</p>
<img src="AI/image-20220816223109918-166193938226932.png" srcset="/img/loading.gif" lazyload alt="image-20220816223109918" style="zoom:50%;" />



<h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><p><img src="/AI/image-20220816224755396-166193938226933.png" srcset="/img/loading.gif" lazyload alt="基于矩阵乘法的单层神经网络前向传播实现"></p>
<p>说明：</p>
<ol>
<li>上图所示是基于<strong>矩阵乘法</strong>的<strong>单层</strong>神经网络<strong>前向传播</strong>实现。即已知模型参数，进行前向传播，也称为模型推理。</li>
<li>np.matmul 指的是调用 numpy 中的矩阵乘法运算。</li>
</ol>
<p><strong>模型训练步骤：（分3步走）</strong></p>
<p><img src="/AI/image-20220817150143427-166193938226938.png" srcset="/img/loading.gif" lazyload alt="image-20220817150143427"></p>
<p>下面是具体的训练神经网络的三个步骤的 Tensorflow 代码：</p>
<p><strong>一、步骤1：确定模型</strong></p>
<p><img src="/AI/image-20220817150414893-166193938226934.png" srcset="/img/loading.gif" lazyload alt="image-20220817150414893"></p>
<p>分析：该步骤搭建好神经网络的结构。</p>
<p>二、步骤2：确定 Loss function or Cost function（即确定模型误差函数，衡量模型的函数、待优化的目标）</p>
<p><img src="/AI/image-20220817151306431-166193938226935.png" srcset="/img/loading.gif" lazyload alt="image-20220817151306431"></p>
<p>说明：对于二元分类问题（结果要么为 0 要么为 1），tensorflow 中采用二元交叉熵函数（Binary Crossentropy）作为神经网络的 loss function。对于回归问题，采用平方误差函数（Mean Squared Error）作为 loss function。</p>
<p>三、步骤3：采用<strong>梯度下降算法</strong>使 loss function 最小，使得模型参数最优。</p>
<p><img src="/AI/image-20220817152255001-166193938226936.png" srcset="/img/loading.gif" lazyload alt="image-20220817152255001"></p>
<p>说明：在 tensorflow 中直接调用 fit 函数即可实现神经网络的<strong>反向传播算法</strong>，这种算法类似解决传统的回归问题而后分类问题的梯度下降算法。epochs 为设置模型训练的迭代次数。</p>
<h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><h4 id="为什么每个神经元需要激活函数"><a href="#为什么每个神经元需要激活函数" class="headerlink" title="为什么每个神经元需要激活函数"></a>为什么每个神经元需要激活函数</h4><p>隐藏层不要使用线性激活函数（相当于没用函数）。</p>
<h4 id="激活函数的种类"><a href="#激活函数的种类" class="headerlink" title="激活函数的种类"></a>激活函数的种类</h4><p>目前深度学习中常用激活函数如下：</p>
<p><img src="/AI/image-20220817153354437.png" srcset="/img/loading.gif" lazyload alt="image-20220817153354437"></p>
<p>常用激活函数：</p>
<ol>
<li><p>线性激活函数：g(z) &#x3D; z；当使用线性激活函数时，有时人们也会说<strong>没有使用激活函数</strong>。</p>
<p>因为 **<code>a = g(wx + b) = wx + b</code>**，相当于没有使用 g 这个函数。</p>
</li>
<li><p>Sigmoid 函数，之前处理分类问题时候曾提到过。</p>
</li>
<li><p>ReLU 函数，<code>g(z) = max(0, z)</code>，当 x &lt; 0 时，g(z) &#x3D; 0；当 x &gt;&#x3D; 0 时，g(z) &#x3D; z。注意和线性激活函数不同。</p>
</li>
</ol>
<h4 id="激活函数的选择"><a href="#激活函数的选择" class="headerlink" title="激活函数的选择"></a>激活函数的选择</h4><ol>
<li><p>对于<strong>输出层</strong>（output layer）</p>
<p><img src="/AI/image-20220817154401670.png" srcset="/img/loading.gif" lazyload alt="image-20220817154401670"></p>
<ul>
<li>如果输出 y 是对应处理二值分类问题，输出层神经元采用 sigmoid 激活函数；</li>
<li>如果处理的是回归问题，例如股票跌涨幅度，输出 y 可正可负，则输出层神经元采用 Linear 激活函数；</li>
<li>如果处理的是回归问题，但是输出 y 要求是大于 0 的场景，则输出层神经元采用 ReLU 函数。</li>
</ul>
</li>
<li><p>对于<strong>隐藏层</strong>（hidden layer）</p>
<p>一般推荐只使用 <strong>ReLU 激活函数</strong>，是目前隐藏层最常用的激活函数（吴恩达教授推荐）。虽然最近几年会有其他一些激活函数如 tanh 激活函数，Leaky ReLU 函数出现，但是这些都只在一些特定的网络中有些许的优势。对于目前一般的应用，选用ReLU 函数足够。</p>
<p>隐藏层选择 ReLU 的理由：</p>
<ol>
<li>ReLU 函数较 Sigmoid 函数等其他函数形式简单，运算速度快。</li>
<li>在进行梯度下降算法的时候需要对激活函数本身求导，ReLU 函数求导方便，且它的函数曲线很陡峭，不像 sigmoid 函数两边很平缓，下降速度慢。因此 ReLU 激活函数的梯度下降过程更加的快速和高效。</li>
</ol>
</li>
</ol>
<p>激活函数选择&amp;模型搭建代码举例：</p>
<p><img src="/AI/image-20220817160917555-166193938226940.png" srcset="/img/loading.gif" lazyload alt="image-20220817160917555"></p>
<h3 id="多分类问题（multiclass-classification）"><a href="#多分类问题（multiclass-classification）" class="headerlink" title="多分类问题（multiclass classification）"></a>多分类问题（multiclass classification）</h3><p>结果不再是0 或 1的二分类问题。例如一张图片中有很多物体，有很多label，不同分类。</p>
<p><img src="/AI/image-20220817165407108.png" srcset="/img/loading.gif" lazyload alt="image-20220817165407108"></p>
<p><img src="/AI/image-20220825094512491.png" srcset="/img/loading.gif" lazyload alt="image-20220825094512491"></p>
<p>多分类问题的神经网络模型（举例说明而已，实际上根据实际问题的不同，模型也不同）</p>
<p><img src="/AI/image-20220825094618162.png" srcset="/img/loading.gif" lazyload alt="image-20220825094618162"></p>
<p>分析：可以看到输出层有三个神经元，每个神经元的输出值分别代表的是有无车，有无大巴，有无行人的概率。</p>
<p>多分类问题采用 Softmax 算法，Softmax 算法是 二分类问题的 logistic 算法的推广。当如下图所示 N &#x3D; 2时，Softmax 算法退化为 logistic 算法。</p>
<p><img src="/AI/image-20220817170412882.png" srcset="/img/loading.gif" lazyload alt="image-20220817170412882"></p>
<p>多分类问题的 Cost Function</p>
<p><img src="/AI/image-20220817171226025.png" srcset="/img/loading.gif" lazyload alt="image-20220817171226025"></p>
<p>注意：</p>
<ol>
<li><p>loss function 指的是单一样本训练的误差，而 Cost function 指的是全体样本参与（全体模型参数参与）的平均训练误差。</p>
</li>
<li><p>对 -log 曲线用于 loss function 的理解：</p>
<p>首先是一个单调下降的曲线，纵坐标为 loss 误差，横坐标为：a，每个神经元中经过 softmax 激活函数算出来的结果，取值范围为(0, 1)。所以 a 的值越靠近 1，代表判断为该结果（标签）的概率越大，代表 loss 误差越小。</p>
</li>
</ol>
<p><img src="/AI/image-20220817172716638.png" srcset="/img/loading.gif" lazyload alt="image-20220817172716638"></p>
<p>注意：Softmax 最后每个神经元的输出是<strong>用的不同的输入z，不是统一的 z，然后统一的表达式输出不同的结果</strong>，这一点一定要注意，这是与其他模型的区别！<strong>每个神经元的 z 的w，b模型参数是不同的</strong>，所以计算输出结果不同。</p>
<p><img src="/AI/image-20220817172729730.png" srcset="/img/loading.gif" lazyload alt="image-20220817172729730"></p>
<p><strong>multi-label classification</strong>（用于图片）</p>
<p>对比一下 multi-label classification 和 multiclass classification：</p>
<p>multiclass classification针对的典型问题如手写识别，例如识别输入的0-9数字。那么对于一个人手写一个数字，最终输出判断的是0-9不同数字的概率，并最终根据这些概率认为输出的数字是最大概率的那个。所以multiclass classification 针对的场景是根据输入，判断唯一分类输出的情况。</p>
<p>multi-label classification针对的典型问题是图片。例如输入一张图片，同时需要判断这张图片上的不同特征，例如是否有猫，是否有狗，是否有人等等，相当于最终的输出带有不同label的特征信息。</p>
<h3 id="高级优化方法"><a href="#高级优化方法" class="headerlink" title="高级优化方法"></a>高级优化方法</h3><p>这里的高级优化方法指的是用于最小化 Cost Function 的一些优化方法。之前提到了我们最小化目标函数的方法采用梯度下降算法，而高级优化方法就是在此基础上对原来传统的梯度下降算法做出一些改进。<strong>优化方法的根本目的是加快模型训练的速度。</strong></p>
<p>需求：有时候我们希望 learning rate（学习率）大一点，这样梯度下降的速度会快一点；而有的时候我们希望学习率小一点，防止无法达到我们损失函数cost function的局部最小值而产生震荡。所以我们需要learning rate 可以自适应的动态调整，因此诞生出Adam算法，<strong>一种学习率自适应的梯度下降算法</strong>。</p>
<p><strong>Adam algorithm</strong></p>
<p><img src="/AI/image-20220825100111084.png" srcset="/img/loading.gif" lazyload alt="image-20220825100111084"></p>
<p>首先，<strong>Adam算法并不是给全局的模型更新参数设置同一个学习率</strong>，而是<strong>不同的参数梯度下降表达式中设置不同的学习率</strong>（如上图所示）。因此若有 n 个模型更新参数，则 Adam 算法首先为他们设置 n 个不同的学习率，每个学习率各自做自适应的动态调整。</p>
<p><img src="/AI/image-20220825100037369.png" srcset="/img/loading.gif" lazyload alt="image-20220825100037369"></p>
<p>其次，根据直觉理解 Adam 算法实现的原理，如上图所示，若发现前后计算的梯度值大致相同，即表示前后两次梯度下降的方向大体不变，此时认为前进方向没错，于是增大学习率，大踏步向前走；而若发现前后两次的梯度下降方向改变频繁，即认为出现震荡，于是减小学习率，小碎步使其收敛。</p>
<p><strong>TensorFlow中实现Adam算法</strong></p>
<p><img src="/AI/image-20220825100912849.png" srcset="/img/loading.gif" lazyload alt="image-20220825100912849"></p>
<p>相比较之前的代码，只需要在 model.compile 中指明需要的 Adam 优化器即可，还需要设置初始学习率，而随后系统将采用 Adam 优化算法进行模型参数的最优化逼近。当然实际调试中可以修改初始学习率的值，来看看哪个初始值更能提高整个模型训练的效率。</p>
<blockquote>
<p>吴恩达教授建议：一般地，Adam算法要比传统的梯度下降算法对模型的训练速度更快。目前，Adam 算法在工业界中已经得到广泛的应用，尤其在神经网络的训练中，一般都建议采用Adam算法来进行模型训练。</p>
</blockquote>
<h3 id="其他的网络层类型"><a href="#其他的网络层类型" class="headerlink" title="其他的网络层类型"></a>其他的网络层类型</h3><p>之前学习的神经网络是一种 Dense Layer 结构，即密集型神经网络，它的隐藏层每个神经元的输出都包含了前一层的所有神经元的输入，是全连接的结构。如下图所示。</p>
<p><img src="/AI/image-20220825101855984.png" srcset="/img/loading.gif" lazyload alt="image-20220825101855984"></p>
<p>另外的，有一种是卷积层结构，即卷积神经网络（CNN）。</p>
<p><img src="/AI/image-20220825102935325.png" srcset="/img/loading.gif" lazyload alt="image-20220825102935325"></p>
<p>分析：区别于密集型层结构的神经网络结构，卷积神经网络的隐藏层中的每个神经源只获取前面部分神经元的输入，只获取部分信息。拿输入的是一张图片来说，卷积神经网络的每个神经元值只提取一张图片中的一部分区域的像素作为输入。这样的结构可以加快计算速度，同时减小了需要的训练数据，一定程度上也能防止过拟合。</p>
<p><strong>卷积神经网络的例子</strong>（注意这是一个一维的例子，而不是例如图像的二维的例子）</p>
<p>根据心电图电压波形来判断这个人是狗患有心脏病。其中x1，x2…x100 表示划分的100个时刻对应的电压。</p>
<p><img src="/AI/image-20220825103639197.png" srcset="/img/loading.gif" lazyload alt="image-20220825103639197"></p>
<p>卷积层神经网络模型结构分析：</p>
<p>如上图所示，可以看到第一层卷积层由9个神经元构成，其中每个神经元分别只看前面10个时刻的电压（即只有前面10个时刻的电压值作为输入）。第二层卷积层由3个神经元构成，其中每个神经元只看前面5个神经元的计算结果（注意：可以有重叠）。最后输出层利用sigmoid函数将前级3个神经元的输入进行综合计算求出该病人患心脏病的概率。</p>
<p>&#x3D;&#x3D;<strong>可以修改卷积神经网络的层级结构、每层的神经元个数、每个神经元获得的前级神经元信息数量来改善网络模型。</strong>&#x3D;&#x3D;</p>
<h2 id="模型训练指导"><a href="#模型训练指导" class="headerlink" title="模型训练指导"></a>模型训练指导</h2><p>本章将学习到一些有效的模型训练方法和技巧，以及如何判断评估一个模型的好坏，以及当模型的结果很糟糕时，我们又如何发现问题，如何调整优化。</p>
<p>例如，如下图所示，当我们之前的房屋预测模型输出结果很差的话，我们如何排查问题，下一步如何做来提升改进模型，提升模型性能。</p>
<p><img src="/AI/image-20220825105424279.png" srcset="/img/loading.gif" lazyload alt="image-20220825105424279"></p>
<h3 id="1-评估模型的好坏"><a href="#1-评估模型的好坏" class="headerlink" title="1. 评估模型的好坏"></a>1. 评估模型的好坏</h3><p>对于一维的线性回归问题，我们可以将拟合曲线画出来和数据进行比较直观的判断模型的好坏。但是若输入特征有很多，不再是一维的情况，那么就很难直观的将图形画出来看到反应模型好坏的图形。</p>
<p>因此更多的时候我们采用一种将模型划<strong>分为训练集和测试集</strong>，利用训练集训练，而利用测试集测试的方法来评估模型的好坏。</p>
<p><img src="/AI/image-20220825110943060.png" srcset="/img/loading.gif" lazyload alt="image-20220825110943060"></p>
<p>上述将样本数据只划分为训练集和测试集的方式有时候并不能保证模型具有很好的泛化能力。更加稳妥的方式是将数据样本划分为测试集，验证集和测试集，利用测试集和验证集来选择模型，利用测试集来评判模型的好坏。</p>
<p><img src="/AI/image-20220825114743843.png" srcset="/img/loading.gif" lazyload alt="image-20220825114743843"></p>
<ol>
<li><p>其中验证集也称为：validation set 或者 development set 或者 dev set，都表示验证集的意思。</p>
</li>
<li><p>在前面只划分训练集和测试集，是否有必要再在测试集中分一个验证集出来？</p>
<p>个人认为这是有必要的，如果不同模型训练好后来比较模型的好坏，只是看测试集误差，可能不同模型之间在计算该测试集误差时其中不同样本误差有大有小，其平均后在外界看来显得测试集误差很小，但是因为其中可能包含有些很大的样本误差，不能说明模型是好的。将测试集进一步划分相当于剖开更仔细地看内部的误差，这样更容易抓出其中大的误差点，更能放大的体现出模型的好坏。</p>
</li>
<li><p>个人理解：将数据样本多划分了一个验证集就好比多加了一门考试，这样通过测试集考一次，再通过验证集期末考再考一次，两次综合评价更能确保你是否真的掌握了知识，是否真的学会了。前面只划分训练集和测试集有点类似于一考定终生，有时候不一定能反映这个人的平均真实稳定水平。</p>
</li>
</ol>
<p>总结起来，一种最有效的模型选择或者模型参数选择的方式就是：先将所有数据样本划分为训练集，（交叉）验证集和测试集。在初步选择模型架构或者训练模型参数的时候只用训练集和验证集。选择的不同的模型分别用训练集进行训练，获得模型参数后分别利用验证集进行验证，计算各种模型的验证集误差，挑选出验证集误差最小的模型作为选择的模型，然后再将该模型及其模型参数用测试集测试，计算测试集误差，从而综合评估模型的好坏（泛化能力）。</p>
<hr>
<h1 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h1><p>课程——同济子豪兄的课程。</p>
<p>推荐 CS231N 课程</p>
<h2 id="第一课"><a href="#第一课" class="headerlink" title="第一课"></a>第一课</h2><h3 id="计算机视觉解决的3大问题——分类，检测，分割"><a href="#计算机视觉解决的3大问题——分类，检测，分割" class="headerlink" title="计算机视觉解决的3大问题——分类，检测，分割"></a>计算机视觉解决的3大问题——分类，检测，分割</h3><p><img src="/AI/image-20220818152444583-1661939503311115.png" srcset="/img/loading.gif" lazyload alt="image-20220818152444583"></p>
<ul>
<li><p>分类（Classification）：可以是二分类，可以是多分类。输入图像，输出判断图像所属的类别。</p>
</li>
<li><p>检测（Object Detection）：利用矩形框将目标框出来。</p>
<blockquote>
<p>其中矩形框只需要两个参数即可画出，矩形框左上角和右下角两点的坐标。</p>
</blockquote>
</li>
<li><p>分割（Segmentation）：如果只是用矩形框标出目标对象，在矩形框内会有很多包含如背景等很多其他的冗余信息，在某些场景下是我们所不需要的，于是需要采用分割的算法，如上图中最右边图所示，分割算法将目标标出。分割技术在无人驾驶领域是非常重要的。</p>
</li>
</ul>
<p>其中，三种问题中，<strong>分割问题最难</strong>。</p>
<ul>
<li><p>分类问题是对整个图像进行分析。</p>
</li>
<li><p>目标检测问题是对定位信息进行分析。</p>
</li>
<li><p>分割问题是对图片像素粒度进行分析。</p>
</li>
</ul>
<p><strong>进一步细分</strong></p>
<p><img src="/AI/image-20220818153921778-1661939503311116.png" srcset="/img/loading.gif" lazyload alt="image-20220818153921778"></p>
<p>说明：上图展示的是计算机视觉解决的不同问题分类。</p>
<ol>
<li>注意目标定位（Object Localization）和目标检测（Object Recognition）的区别。如上图中第一行的后两张图对比。</li>
<li>注意语义分割（Semantic Segmentation）和 实例分割（Instance Segmentation）的区别。<ul>
<li>语义分割是将一幅图上判断为同一类别的物体用同样的颜色表示出来，例如上图中第二行的第一张图，所有的羊被认为是同样的一个整体，认为是同一个物体。</li>
<li>实例分割是将一幅图上的不同实例（不同的个体对象）全部分割区分开来。例如上图中第二行的第二张图，虽然都为羊，但是是不同实例（对象），于是将其每个实例分割区分开来。这在自动驾驶领域十分重要。</li>
</ul>
</li>
<li>上图中第二行的最后一张图为关键点检测。提取目标对象关键点信息，例如关节，即可获取其姿态和运动状态等。有望应用于当前的动漫动作捕捉行业以及例如篮球等运动分解、教学领域。</li>
</ol>
<p><strong>分类问题</strong>：判断一幅图中目标对象所属的种类。（一般这类问题中图片中只会出现一个对象，例如手写输入文字识别）</p>
<p><img src="/AI/image-20220818155336123-1661939503311117.png" srcset="/img/loading.gif" lazyload alt="image-20220818155336123"></p>
<p><strong>目标检测问题</strong>：用画矩形框的形式框出一幅图上不同的物体对象。</p>
<img src="AI/image-20220818155245104-1661939503311118.png" srcset="/img/loading.gif" lazyload alt="image-20220818155245104" style="zoom: 80%;" />



<p><strong>语义分割</strong>：像素级的检测分割。将判断为同一个label，同一个类别的物体对象在像素级尺度上分割为一类，用相同的颜色表示。注意此时不区分不同的实例。</p>
<p><img src="/AI/image-20220818155359103-1661939503311119.png" srcset="/img/loading.gif" lazyload alt="image-20220818155359103"></p>
<p><strong>实例分割</strong>：像素级的分割。将一幅图上的不同实例都在像素级尺度上单独分割出来。</p>
<p><img src="/AI/image-20220818155412509-1661939503311120.png" srcset="/img/loading.gif" lazyload alt="image-20220818155412509"></p>
<p><strong>关键点检测</strong>：例如检测人体的各关节。</p>
<p><img src="/AI/image-20220818155421399-1661939503311121.png" srcset="/img/loading.gif" lazyload alt="image-20220818155421399"></p>
<h3 id="计算机视觉发展前沿"><a href="#计算机视觉发展前沿" class="headerlink" title="计算机视觉发展前沿"></a>计算机视觉发展前沿</h3><p>深度学习-计算机视觉</p>
<p>深度学习三驾马车：算力（硬件），数据（特别是海量的经过标注好的数据，例如 ImageNet 图像数据集），算法（如何高效的训练一个很深的神经网络，防止其过拟合）</p>
<p>ImageNet：由斯坦福大学华人科学家李飞飞教授提出。有几百万张经过标注好的分类图片。</p>
<p>下图是 ImageNet 举办的<strong>图像分类</strong>比赛，2017年停止举办。</p>
<p><img src="/AI/image-20220818170040695-1661939503311122.png" srcset="/img/loading.gif" lazyload alt="image-20220818170040695"></p>
<p>分析图片：横坐标为举办比赛的年份以及获得冠军队伍采用的神经网络框架，纵坐标为图像分类的错误率。</p>
<p>重要关键时间点：</p>
<ol>
<li>2012年 AlexNet 横空出世，首次在图像分89中使用深度学习中的卷积神经网络，且识别图像错误率大幅度下降。</li>
<li>2014年 Google 推出 GoogleNet。</li>
<li>2015年由中科院提出的 ResNet 图像分类识别错误率首次低于人类，首次超过人类（人类的错误识别率入如图所示在 5%-10%）。错误率在 5% 以内。于是在2017年结束后，人们认为图像分类领域已经达到很高的程度，于是停止了该图像分类比赛。</li>
</ol>
<p>&#x3D;&#x3D;不禁感慨，短短 8 年，计算机视觉在图像分类领域取得了如此卓越的进步。&#x3D;&#x3D;</p>
<p><img src="/AI/image-20220818171819211-1661939503311123.png" srcset="/img/loading.gif" lazyload alt="image-20220818171819211"></p>
<p>图片说明：上图展示的是计算机视觉中图像分类技术的发展。横坐标为时间，纵坐标为分类误差。</p>
<p>其中关键的时间结点是 2012 年 AlexNet 的横空出世开启了图像分类的新纪元。首次引入深度学习中的卷积神经网络。而在 2012 年以前还是采用传统的特征工程的方法人为的提取出图片不同的特征。而卷积神经网络是自动的提取出图片特征。</p>
<p>因为图像分类领域已经处于一个很高的水平，技术相对成熟，于是科学家们又转战到计算机视觉的另一个领域——目标检测。</p>
<p><img src="/AI/image-20220818172442170-1661939503311124.png" srcset="/img/loading.gif" lazyload alt="image-20220818172442170"></p>
<p>图片说明：上图最上方的云梯图展示了目标检测技术的发展过程和重要时间点关键的技术。</p>
<p>可以初步划分为两个阶段：</p>
<ul>
<li><p>两阶段目标检测：在 YOLO 提出以前，属于两阶段的目标检测。所谓两阶段，是指目标检测分为两个阶段：1. 先从图像中提取出很多很多候选框；2. 再逐个分别分析每个候选框内的图像内容，最后将置信度高的候选框挑选出来，展示最终的目标检测结果。重要的典型算法如 R—CNN，第一次将 CNN 卷积神经网络用于目标检测里面。</p>
<p>两阶段目标检测的缺点：算法执行效率很慢，但精确率很高。</p>
</li>
<li><p>单阶段目标检测：例如 2016 年提出 YOLO 模型（重要时间结点），是单阶段目标检测方法，它不需要提出候选框，直接将图片输入即可得到目标检测结果。特点是算法执行效率非常快，模型运行速度很快。</p>
</li>
</ul>
<h2 id="第二课——安装openCV"><a href="#第二课——安装openCV" class="headerlink" title="第二课——安装openCV"></a>第二课——安装openCV</h2><ul>
<li>Step 1：下载 python 解释器，直接官网下载即可。安装成功提示如下图，配置好 python 环境变量后在 windows 的命令行窗口输入：python，显示安装的 python 解释器对应版本号即代表安装成功。</li>
</ul>
<p><img src="/AI/image-20220819225125424-1661939503311127.png" srcset="/img/loading.gif" lazyload alt="image-20220819225125424"></p>
<ul>
<li><p>Step 2：pip 切换镜像源。</p>
<p><img src="/AI/image-20220819233744661-1661939503311125.png" srcset="/img/loading.gif" lazyload alt="image-20220819233744661"></p>
<blockquote>
<ol>
<li><p>pip 类似一个全部基于 python 开发的 app 应用商场。</p>
</li>
<li><p>注意 pip <strong>不是 python 命令</strong>，是基于<strong>操作系统的命令</strong>，所以应该直接在<strong>命令行（cmd）输入</strong>对应指令而不要在 python 命令行<code>&gt;&gt;&gt;</code>输入。</p>
</li>
<li><p>切换镜像源可以加快应用文件的下载速度。相当于国内的某人已经帮你下好了，你直接从他那下，不用去到外网。</p>
</li>
</ol>
</blockquote>
<p>国内目前有很多镜像源，较好用的例如阿里云镜像站，清华大学镜像站等高校镜像站。</p>
<ul>
<li><p>将 pip 的<strong>下载源</strong>永久切换为<strong>阿里云的镜像站</strong></p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vim">pip config <span class="hljs-keyword">set</span> <span class="hljs-keyword">global</span>.<span class="hljs-built_in">index</span>-url https://mirrors.aliyun.<span class="hljs-keyword">com</span>/pypi/simple/<br></code></pre></td></tr></table></figure>
</li>
<li><p>将 pip 的<strong>下载源</strong>永久切换为<strong>清华的镜像站</strong></p>
<figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gams">pip config <span class="hljs-keyword">set</span> global.index-url <span class="hljs-comment">https:</span>//<span class="hljs-comment">pypi.tuna.tsinghua.edu.cn</span>/simple/<br></code></pre></td></tr></table></figure></li>
</ul>
<p>补充：</p>
<p><img src="/AI/image-20220819234009147-1661939503311126.png" srcset="/img/loading.gif" lazyload alt="image-20220819234009147"></p>
<p><img src="/AI/image-20220819234126710-1661939503311128.png" srcset="/img/loading.gif" lazyload alt="image-20220819234126710"></p>
</li>
<li><p>Step 3：安装 python—opencv（最好在这一步之前切换一下pip安装文件的默认路径，一般默认安装在C盘，建议改在别的盘，具体操作直接百度即可。）</p>
<p>Windows <code>cmd</code> 命令行窗口直接输入下面语句即可安装。用阿里云的镜像源下载还是很快的。</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">pip <span class="hljs-keyword">install</span>  opencv-python<br></code></pre></td></tr></table></figure></li>
</ul>
<p>通过 <code>pip list</code> 命令查看，若有 <code>opencv-python   4.6.0.66</code> 信息则表示安装成功（版本号可能不同，出现有就行）。至此 opencv 安装完成！</p>
<hr>
<h1 id="深度学习硬件配置"><a href="#深度学习硬件配置" class="headerlink" title="深度学习硬件配置"></a>深度学习硬件配置</h1><h2 id="显卡"><a href="#显卡" class="headerlink" title="显卡"></a>显卡</h2><h1 id="Windows-深度学习环境搭建"><a href="#Windows-深度学习环境搭建" class="headerlink" title="Windows 深度学习环境搭建"></a>Windows 深度学习环境搭建</h1><p><strong>第一步：安装CUDA</strong></p>
<p>前言：CUDA（Compute Unified Device Architecture） 是 NVIDIA 推出的一种并行计算平台和编程模型。它通过利用图形处理器 (GPU) 的处理能力，可大幅提升计算性能。可以理解为厂家提供了一个平台方便用户调用GPU实现高效的并行能力。只有NVidia显卡才能使用CUDA。当然用户也可以不使用CUDA，直接面向显卡驱动接口也可以调用GPU，当然由于这种方案很不友好。所有NVIDIA推出了更加高效便捷的CUDA。(来源于网络)</p>
<ul>
<li><p>1）查看本机显卡驱动版本号，从而确定安装的 CUDA 版本号。（有两种方法，其中方法2更简单）</p>
<ul>
<li>方法1：桌面右击进入NVIDIA控制面板——&gt;点击左下角的系统信息——&gt;查看驱动版本号。具体步骤如下图所示，所以得到本机的驱动版本号为：511.79。</li>
</ul>
<img src="AI/image-20220828112522500-1661939559664143.png" srcset="/img/loading.gif" lazyload alt="image-20220828112522500" style="zoom: 80%;" />

<img src="AI/image-20220828112806636-1661939559664144.png" srcset="/img/loading.gif" lazyload alt="image-20220828112806636"  />



<ul>
<li><p>方法2：桌面右击进入NVIDIA控制面板——&gt;点击左下角的系统信息——&gt;组件，直接查看本机的CUDA支持的版本。可以看到本机的显卡支持CUDA 11.6版本，于是可以直接去CUDA官网下载CUDA11.6 版本的CUDA Toolkit 即可。</p>
<p><img src="/AI/image-20220828130610498-1661939559664145.png" srcset="/img/loading.gif" lazyload alt="image-20220828130610498"></p>
</li>
</ul>
</li>
<li><p>2）浏览器直接搜索 CUDA，进入 CUDA 官网，下载对应版本的 CUDA 安装包。</p>
<p>比对下表（下表是在进入 CUDA 官网后找到 Release Notes 链接，然后点击进去下拉找到 Table3），因为上一步得知本机显卡驱动版本为511.79，因此选择 CUDA 11.6 Update 2 进行安装。</p>
<p><img src="/AI/image-20220828113641777-1661939559664146.png" srcset="/img/loading.gif" lazyload alt="image-20220828113641777"></p>
</li>
<li><p>3）直接点击前面下载好的CUDA安装包进行安装即可。</p>
<p>选择自定义安装，修改安装位置，然后等待安装结束即可。安装后系统会自动添加环境变量。</p>
<p><img src="/AI/image-20220828132927367-1661939559664147.png" srcset="/img/loading.gif" lazyload alt="image-20220828132927367"></p>
<p><img src="/AI/image-20220828135503321-1661939559664148.png" srcset="/img/loading.gif" lazyload alt="image-20220828135503321"></p>
</li>
<li><p>4）查看是否CUDA安装成功。</p>
<ul>
<li><p>方法1：</p>
<p>Windows 命令行窗口输入：<code>nvcc -V</code>（注意：是大写的V），出现类似下面信息则表示安装成功。</p>
</li>
</ul>
<p><img src="/AI/image-20220828135715221-1661939559664149.png" srcset="/img/loading.gif" lazyload alt="image-20220828135715221"></p>
<ul>
<li><p>方法2：</p>
<p>Windows 命令行窗口输入：<code>nividia-smi</code> (注意：nividia 和 -smi 之间没有空格)</p>
<p><img src="/AI/image-20220828141452704-1661939559664150.png" srcset="/img/loading.gif" lazyload alt="image-20220828141452704"></p>
<p>可以看到本机上的显卡型号以及安装好的CUDA版本为11.6。</p>
</li>
</ul>
</li>
</ul>
<p><strong>第二步：安装 conda (通过安装Anaconda 或者 Miniconda 来间接获得 conda)</strong></p>
<p>Q1：为什么需要安装 conda？</p>
<p>A：运行不同的项目依赖的 pytorch 和 python 等版本不同，所以我们有安装不同版本的需求。<strong>conda 可以帮我们安装多个版本的软件包及其依赖关系，并在它们之间轻松切换</strong>。</p>
<p>Q2：怎么安装 conda？</p>
<p>A2：Anaconda，Miniconda 是包含了很多工具的集合，它们都包含了<strong>conda、Python包及其依赖项</strong>，安装它们就具备了conda 的环境。</p>
<p>Q3：Anaconda 和 Miniconda 的区别？</p>
<p>A3：Anaconda 含有的包等资源内容更丰富，Miniconda 可以理解为 Anaconda 的精简版。</p>
<p>这里选用安装 Miniconda，以下为安装步骤。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" class="category-chain-item">人工智能</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="print-no-link">#学习笔记</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>AI</div>
      <div>http://example.com/2022/06/15/AI/</div>
    </div>
    <div class="license-meta">
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2022年6月15日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/06/04/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" title="windows下深度学习环境配置-PyTorch安装">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">windows下深度学习环境配置-PyTorch安装</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
