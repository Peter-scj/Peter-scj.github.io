<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/06/04/%E5%AE%9E%E9%AA%8C%E6%B5%8B%E8%AF%95%E6%AD%A5%E9%AA%A4/"/>
    <url>/2024/06/04/%E5%AE%9E%E9%AA%8C%E6%B5%8B%E8%AF%95%E6%AD%A5%E9%AA%A4/</url>
    
    <content type="html"><![CDATA[<h1 id="实验测试步骤"><a href="#实验测试步骤" class="headerlink" title="实验测试步骤"></a>实验测试步骤</h1><ol><li>MQTT服务器测试运行。<ol><li><code>阿里云服务器运行检查</code> <code>https://ecs.console.aliyun.com/server/region/cn-heyuan#/</code>查看阿里云服务器是否运行。</li><li>MQTT控制台检查，是否运行MQTT服务器脚本。 通过<code>http://47.120.10.197:18083</code>访问MQTT的Dashboard控制台。 user: admin，passwd:1092387456jsc!!</li><li>本地打开MQTTX客户端，发送msg观察Dashboard测试。</li></ol></li><li>摄像头和主控板配网。 需要局域网，wifi或者开热点。首先需要获得WIFI 的 ip 地址和 WiFi 账户和密码。<ol><li>摄像头配网：<ol><li>短接线5s左右，听到滴声，进入默认AP模式。wifi搜索Cam_XXXX.</li><li>IP地址：192.168.200.1，打开SAT模式，选择WIFI，输入密码，然后配网成功。</li></ol></li><li>主控板配网：<ol><li>在stm32主控程序中，esp8266.c文件：</li><li>修改wifi名称和密码：<code>#define ESP8266_WIFI_INFO    &quot;AT+CWJAP=\&quot;TP-LINK_C6A424\&quot;,\&quot;lab302302\&quot;\r\n&quot;</code></li><li>修改MQTT服务器IP地址： <code> #define ESP8266_ONENET_INFO   &quot;AT+CIPSTART=\&quot;TCP\&quot;,\emqx@47.120.10.197\&quot;,1883\r\n&quot;</code></li></ol></li></ol></li><li>手机遥控实现自检测试。test</li><li>手机远程控制采集图像。<ol><li>前进，后退，旋转转台。图片和视频本地保存。上位机设计。</li></ol></li></ol><h1 id="My-PipeLine-Robot-APP使用指南"><a href="#My-PipeLine-Robot-APP使用指南" class="headerlink" title="My PipeLine Robot APP使用指南"></a>My PipeLine Robot APP使用指南</h1><p><img src="https://d0z4vd8gz1i.feishu.cn/space/api/box/stream/download/asynccode/?code=NTI3NzA2ZGM3YTViNTVhY2I0NjQyNzA0ZjQ0NzkwOTNfN1JzTjlVbmlMOU16aUZKRlR0WHY5ZXZyMVRXd2ZlWE5fVG9rZW46SkUwcmI5WlN5b1Vrdmd4Z0MzdWNrMHBoblNiXzE3MTc0NzQxNzU6MTcxNzQ3Nzc3NV9WNA" alt="img"></p><p>长按才能设置速度。</p><h1 id="EMQX"><a href="#EMQX" class="headerlink" title="EMQX"></a>EMQX</h1><p>采用EMQX开源版进行部署</p><p><a href="https://www.emqx.io/docs/zh/latest/getting-started/getting-started.html">https://www.emqx.io/docs/zh/latest/getting-started/getting-started.html</a></p><p>注意：如果运行不起需要额外安装C++系统库。直接百度搜官网下载安装即可。</p><ul><li><code>http://localhost:18083/</code>查看MQTT控制台</li><li>公网ip<ul><li><code>47.120.10.197</code></li><li>通过<code>http://47.120.10.197:18083</code>访问MQTT的Dashbaoard控制台。passwd:1092387456jsc!!</li><li>其他连接的设备采用1883连接。即：<code>http://47.120.10.197:1883</code></li></ul></li></ul><p><img src="https://d0z4vd8gz1i.feishu.cn/space/api/box/stream/download/asynccode/?code=YTM3ZTY1ZGQ5ZWNlYzI1NzA1YzA1MDEwMDViMDA0YmNfOTl1MUl4MjZFMURXU3BMMDV2b3YwOEVOUHVuT0Y1TnpfVG9rZW46VWd3MGJRdk9mb3pkbWN4bmVhOGNZdkRWbjZjXzE3MTc0NzQxNzU6MTcxNzQ3Nzc3NV9WNA" alt="img"></p><ul><li>passwd:ek&#x3D;hv-w0</li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>windows下深度学习环境配置-PyTorch安装</title>
    <link href="/2024/06/04/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    <url>/2024/06/04/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
    
    <content type="html"><![CDATA[<h1 id="windows下Pytorch深度学习环境配置"><a href="#windows下Pytorch深度学习环境配置" class="headerlink" title="windows下Pytorch深度学习环境配置"></a>windows下Pytorch深度学习环境配置</h1><ul><li><p>在进行深度学习环境配置时，需要下载python，但是不要直接去官网 download python。<br>我们通过别的方式安装下载python环境。</p></li><li><p>库&#x2F;包&#x2F;package&#x2F;library<br>别人分享的工具和模板。<br>例如：</p><ul><li>matplotlib：matlab用python封装好的包，用于利用python画图。</li><li>pytorch<br>tensorflow<br>以上两个包用于深度学习</li><li>numpy：用于科学计算的python包</li></ul></li><li><p>利用pip命令安装python包。pip类似于手机上的应用商城。相当于在python的应用商店pip内安装install各种提供好的软件。<br><code>pip install matplotlib</code><br><code>pip insatll 包名</code></p></li><li><p>Pytorch 和 Tensorflow<br>Pytorch 和 Tensorflow 其实就是前面介绍的python的包&#x2F;库。是专门用于深度学习的python包（库）。安装其实就是pip install 包名的过程。</p></li><li><p>Anaconda<br>下载Anaconda后会提供python环境和Conda命令，conda和pip类似，其实都是相当于我们手机上的应用商城，可能一个类似于小米商城，一个类似于华为商城。我们都可以通过这样的命令加上install下载属于这个应用商城内的软件。</p><p><strong>conda和pip都是python的包管理工具。</strong></p><p>但是做深度学习的环境配置我们一般喜欢采用conda命令进行python包的下载，而不用pip，原因是conda有虚拟环境的概念。即他会为不同版本的python分别创建独立的环境，不同版本的python及其所属的安装包可以独立存在，且互不影响。这样，我们可以根据不同项目的实际需要下载多个不同版本的python，由anaconda提供的不同虚拟环境为我们管理这些不同环境即可。而pip则相反，pip仅对应电脑上当前默认的python版本（即我们通过python官网直接download下载的版本，这种下载方式不允许下载多个不同版本的python，如果需要更换其他版本，则需要将当前版本先卸载，然后再下载安装新的版本）。</p><p><strong>为避免python版本冲突，在安装anaconda前最好先卸载自己电脑上之前已经通过python官网download的python，然后再去下载anaconda，用anaconda统一管理电脑上的python环境。</strong></p><p><img src="/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/image-20230523100408729.png" alt="Anaconda"></p><p>在anaconda中我们可以为不同的虚拟环境起不同的名字，通过命令切换环境名字就可以实现切换不同的python环境。</p><p>各个不同的环境的目录是在anaconda的安装目录下的env目录下进行管理。</p><p>安装完anaconda默认会创建一个环境，叫做：base，该环境下默认会安装有很多的conda提供的库（包），主要用于科学计算。</p><p><code>conda env list</code>: 查看当前anaconda管理下存在的所有虚拟环境。（默认会有base，这是安装anaconda就会创建的）</p><p><code>conda list</code>: 查看当前python环境下安装的所有库，类似于pip list。</p><p><code>conda activate Peter</code>：激活、进入名为Peter的python虚拟环境。</p><p><code>conda deactivate</code>: 不激活，即退出该虚拟环境</p></li><li><p>可以通过anaconda提供的图形化界面创建不同的python虚拟环境并且安装库，可以通过anaconda的命令行来进行创建和安装，相比较而言，用命令行安装速度会更快一些。</p></li><li><p>anaconda命令行终端和windows上的cmd命令行终端的区别：<br>anaconda命令行终端打开默认进入的是base虚拟环境目录，前面会带有括号：(base)。而windows上的cmd只会默认在当前打开的目录。可以通过windows默认的cmd终端内输入<code>conda activate base</code>进入到虚拟环境，和通过anaconda终端进入虚拟环境base的效果是一样的。</p></li><li><p>anaconda里面的每一个虚拟环境中都可以安装一个python解释器，其中python解释器的版本可以自己决定。</p></li><li><p>pytorch主要分为：1.0版本之前，很老的版本和1.0之后的版本（Pytorch 1.0 之后逐步走向成熟），现如今已经有2.0版本了。</p></li><li><p>Pycharm<br>python-python解释器（翻译官）-计算机</p><p>前面说的anaconda下的不同的python版本环境其实 本质上就是不同的python解释器。</p><p>创建新的Pycharm项目时：</p><ol><li>先为项目起一个名称，然后选择项目保存的位置。</li><li>为项目选择一个python解释器，即为项目选择&#x2F;创建一个虚拟环境。<br>选择python解释器时可以选择anaconda安装目录下里面的env环境中的python解释器，也可以用base环境下的python解释器，base环境下的python解释器直接在anaconda的安装目录下，而不是env目录下。</li></ol></li><li><p>显卡GPU及其相关概念</p><ul><li>只有Nvidia的显卡才能用于深度学习训练，而英伟达的显卡不行。</li><li>英伟达为开发者提供了一种CUDA编程语言，可以利用CUDA语言向显卡发送指令从而可以操作英伟达的显卡。</li><li>显卡—显卡驱动—计算机识别<br>需要安装对应显卡的驱动才能让计算机识别到特定的显卡硬件。</li></ul></li></ul><p><img src="/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/image-20230523110155659.png" alt="显卡驱动、显卡软件CUDA与Pytorch等的关系"></p><ul><li><p>注意：上图中的CUDA runtime version和CUDA Driver Version不是同个东西，相差甚远。<br>CUDA runtime version指的是软件层面的CUDA，换言之这个才是我们熟知的CUDA编程语言。而驱动层的CUDA driver version是显卡硬件的驱动。<strong>我们在pytorch官网看到的需要安装的cuda指的是cuda runtime version。指的是软件层面的CUDA</strong></p></li><li><p>GPU和CPU的区别</p><p><img src="/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/image-20230523105911447.png" alt="CPU和GPU的区别"></p><p>GPU相比如CPU 有更多的逻辑处理单位ALU，可以并行处理很多简单重复的任务。</p><p>CPU可以通过复杂的控制逻辑可以优化处理<strong>复杂的任务</strong>。GPU可以并行处理大量<strong>简单重复的任务</strong>。</p><p>深度学习并不一定需要使用GPU，有无GPU并不影响深度学习模型最后的训练效果，只是GPU可以加快深度学习的训练速度，大大缩短训练时间。</p><p><img src="/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/image-20230523112114166.png" alt="深度学习中各软件的关系"></p></li><li><p>计算机中安装anaconda和pycharm。<br>anaconda负责管理不同的python环境以及在该环境下安装的不同的库（包），包括tensorflow，pytorch，cuda(如果需要用到GPU进行训练时需要安装)等。<br>pycharm是poython IDE，用来写python代码以及代码的debug。</p><p>用pycharm写好代码后，并且配置好该项目代码所用到的python解释器（python环境），而后将调用该环境中的各种库，利用该环境的python解释器在计算机CPU中来对代码进行解释执行，如果过程中需要用到GPU进行训练，还需要在anaconda中安装cuda库（包），这样当CPU执行到需要用GPU执行的语句时，会发送指令给到GPU从而实现在GPU上进行训练。</p></li></ul><h1 id="正式开始安装"><a href="#正式开始安装" class="headerlink" title="正式开始安装"></a>正式开始安装</h1><p><img src="/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/image-20230523113507247.png" alt="安装基本流程"></p><p>第一步：下载anaconda</p><p><img src="/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/image-20230523113627864.png" alt="anaconda官网"></p><ul><li>注意：以上是anaconda官网显示的信息，表示如果安装该版本的anaconda，其虚拟环境中最高可以支持安装3.9版本的python解释器。所以：对于anaconda的下载，下载最新版本即可，这样支持的python解释器更多，方便后面配置。</li></ul><p>第二步：在下载好的anaconda下创建虚拟环境（也可以不安装，默认用base环境也行）。</p><p><img src="/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/image-20230523143014725.png" alt="创建虚拟环境"></p><ul><li>建议在虚拟环境中安装的python版本高于3.5以上，例如3.6版本。</li><li>在anaconda下的终端执行常用conda指令如下：<ul><li>创建虚拟环境指令：<code>conda create -n 虚拟环境名字 python=版本</code></li><li>删除虚拟环境及其环境中的所有安装库（包）的指令：<code>conda  remove -n 虚拟环境名字 -all</code> </li><li>进入对应虚拟环境的指令：<code>conda activate 虚拟环境名字</code></li><li>退出当前虚拟环境的指令：<code>conda deactivate</code></li></ul></li></ul><p>在进行第三步前的准备工作：</p><p><img src="/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/image-20230523150039101.png" alt="GPU版本安装需要注意的事项（CUDA）"></p><ul><li><p>cuda runtime（软件cuda） 的版本要小于 cuda driver（硬件驱动）的版本。</p></li><li><p>显卡对应的算力可以在nividia官网查询。<a href="https://www.nvidia.cn/geforce/graphics-cards/compare/">NVIDIA显卡cuda算力查询</a></p><p><img src="/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/image-20230523150818673.png" alt="显卡对应CUDA算力"></p></li></ul><h1 id="举例分析"><a href="#举例分析" class="headerlink" title="举例分析"></a>举例分析</h1><ol><li><p>查看显卡型号。<br>RTX3090</p></li><li><p>查看显卡CUDA算力（Compute Capability）。<br>显卡对应的算力可以在nividia官网查询。<a href="https://www.nvidia.cn/geforce/graphics-cards/compare/">NVIDIA显卡cuda算力查询</a>。<br>查询可知 RTX3090 对应的算力(CUDA能力)为8.6</p></li><li><p>确定CUDA Runtime。（即cuda软件SDK的版本）<br>根据上面第1步和第2步知道的我们显卡对应的算力，从而选择满足我们显卡算力要求的 CUDA Runtime Version。<a href="https://en.wikipedia.org/wiki/CUDA#GPUs_supported">CUDA算力对应可以使用的CUDA SDK</a><br>如下表所示，因为我们的显卡算力为8.6，所以支持该算力的CUDA SDK Version应当大于等于11.1以上。即我们在安装pytorch时选择的CUDA Runtime Version 应当大于等于 11.1。</p><p><img src="/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/image-20230523162618799.png" alt="CUDA算力对应的CUDA Runtime Version"></p></li><li><p>查看自己的显卡硬件驱动（CUDA driver version）<br>打开cmd，输入命令：<code>nvidia-smi</code> 查看。<br>如下图所示：本机的显卡硬件驱动版本为：512.15，可以支持的最高CUDA Runtime 版本为：11.6。（显卡硬件驱动必须高于cuda runtime version）</p><p><img src="/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/image-20230523160053442.png" alt="查看显卡硬件驱动 CUDA driver version"></p></li></ol><p>综上：第3步可知我们的显卡必须使用11.1版本以上的 CUDA Runtime Version，而第4步可知显卡当前的硬件驱动可支持最高位11.6版本的 CUDA Runtime Version。因此当前环境下我们可以选用的 CUDA Runtime Version 为：11.1~11.6之间，在不升级显卡硬件驱动的情况下，我们可以选择最新版本，即11.6版本即可。即在安装Pytorch时选择的CUDA版本为11.6.</p><p><img src="/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/image-20230523164424470.png" alt="增加镜像通道"></p><ul><li><p>conda管理的包默认从default路径下载库&#x2F;包。default路径是anaconda的国外服务器，所以一般用默认路径下载一些包时会比较慢，因此可以采用一些国内的镜像网站进行下载。</p><blockquote><ul><li>在我们在anaconda里面创建一个新的虚拟环境时（这个过程也需要下载一些python库），或者利用conda install下载新的库&#x2F;包时，默认都会从default路径去下载。</li><li><strong>default默认下载源的优先级是最低的</strong>，如果向anaconda的配置文件config中添加新的下载源，那么新的下载源的优先级将高于default，并且最高优先级为最近一次添加的下载源。<br>每次下载python库&#x2F;包时会先从高优先级的下载源查找，如有则从高优先级的下载源下载，如果没有再逐次到低优先级的下载源查找，直到找到我们需要下载的资源。</li></ul></blockquote></li><li><p><code>conda config --get</code> 或者 <code>conda config --show</code> 查看当前配置文件中有哪些下载源。<br><code>conda config --add channels 镜像（通道）地址</code>：在anaconda的配置文件config中添加新的通道（镜像源）地址。<br><code>conda config --remove channels 镜像（通道）地址</code>：在anaconda的配置文件config删除通道（镜像源）地址。</p><blockquote><p>config 参数指的是对anaconda的初始配置文件进行操作。</p></blockquote></li><li><p>当然，通过镜像源下载python库也可以采用不修改配置文件的方式，在每次下载包时后面增加 <code>-c 通道地址</code> 选项即可。</p><p><code>conda install matplotlib -c 镜像源地址</code></p><p><strong>推荐采用这种方法下载python库，而不是修改anaconda配置文件</strong>，每次下载的时候如果原网站很慢则加 -c 选项更换镜像源，这样可以避免很多奇奇怪怪的问题。</p></li></ul><h1 id="简单操作（常规操作）"><a href="#简单操作（常规操作）" class="headerlink" title="简单操作（常规操作）"></a>简单操作（常规操作）</h1><p>这也是我们配置深度学习环境的实际常规操作，而不是像上面举例那样复杂。</p><ol><li><p>安装&#x2F;更新显卡硬件驱动，将本机上的显卡驱动更新到最新的版本。<a href="https://www.nvidia.cn/Download/index.aspx?lang=cn">显卡驱动下载</a></p><blockquote><p>虽然不更新驱动也行，但是更新显卡驱动为最新版本可以避免很多问题，并且最新版本也意味着可以最大限度的发挥显卡的性能。推荐更新。</p></blockquote></li><li><p>cmd 终端输入 <code>nvidia-smi</code> 查看更新硬件驱动后本机显卡可支持的最高CUDA Version（CUDA Runtime Version，注意这里是指CUDA软件版本而不是CUDA算力）。<br>如下图所示更新显卡硬件驱动后我的显卡可支持最高12.1的CUDA Runtime Version。因此只需要保证在安装Pytorch时的CUDA版本低于12.1即可，选择小于12.1且最接近的12.1的那个最新版本。</p><p><img src="/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/image-20230523172456277.png" alt="nvidia-smi 查看最高可支持的CUDA Version"></p></li><li><p>打开PyTorch官网，确定CUDA Runtime版本。</p></li></ol><p>第三步：安装 PyTorch（两种方法：1. 使用conda下载安装。2. 使用pip下载安装）</p><ul><li><p>安装 PyTorch其实是安装3个包：pytorch，torchvision和torchaudio。<br>其中pytorch是核心，而torchvision是专门用于图像处理的，torchaudio是专门用于语音的。</p></li><li><p>若是用GPU训练：<br>使用conda需要下载4个包：pytorch，torchvision，torchaudio，toolkit&#x3D;11.6指定版本号。<br>使用pip只需要下载3个包：torch，torchvision, torchaudio。其中toolkit被拆分到了torch里面，所以pip下载的torch比用conda下载的pytorch大很多，但是pip下载速度一般会比用conda下载快一些。</p><blockquote><p>用pip下载如果还是很慢，可以将pip下载的地址（wheel地址，wheel地址与pip有关）复制，然后利用迅雷进行下载。</p></blockquote></li><li><p><strong>注意：确认下载前仔细查看一下下载的pytorch版本以及cuda版本是否是选择的版本！尤其是切换为国内镜像源的情况下，仔细查看一下，免得下载错误造成麻烦！</strong></p><p><img src="/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/image-20230523221130402.png" alt="确认下载前仔细核对下载的pytorch cuda版本号"></p></li><li><p><strong>如果速度不慢，推荐从官网下载，以防出现奇怪的错误！</strong></p></li></ul><p>方法1：用conda进行下载</p><ol><li><p>打开anaconda终端，进入需要安装pytorch的虚拟环境。<br>conda activate …</p></li><li><p>进入pytorch官网，选择好需要下载的pytorch版本以及cudu runtime version，然后利用官网提供的conda命令进行下载。</p><blockquote><p>官网利用conda下载默认的下载地址为 -c pytorch，即pytorch源，而pytorch包比较大，一般1~2个G，所以下载会很慢，可以通过更换下载镜像源来加快下载速度。</p></blockquote></li></ol><p><img src="/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/image-20230523220654637.png" alt="利用conda命令下载安装pytorch"></p><p>方法2：用pip进行下载</p><p><img src="/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/image-20230523215443989.png" alt="用pip命令下载安装pytorch"></p><ul><li>pip install 和 pip3 install作用相同，用 pip install 就好。</li><li><strong>由于torch包比较大</strong>，一般1，2个G，为了进一步加快torch下载速度，可以把pytorch官网提供的用pip下载的url复制，然后用迅雷进行本地下载，然后下载好后打开anaconda终端，进入需要安装torch包的虚拟环境（conda activate …），然后pip install …（将该文件拖入终端获得地址）即可<strong>离线安装torch包</strong>。</li><li>由于torchvision、torchaudio包一般都比较小，大概几M左右，所以可以通过官方的网站进行下载。</li></ul><p>验证pytorch是否安装成功</p><p><img src="/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/image-20230523223244776.png" alt="验证pytorch是否安装成功的步骤"></p><p><img src="/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/image-20230523223543980.png" alt="pytorch安装成功演示"></p><h1 id="安装-pycharm"><a href="#安装-pycharm" class="headerlink" title="安装 pycharm"></a>安装 pycharm</h1><p>配置pycharm项目的python解释器</p><p>step1：</p><p><img src="/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/image-20230523230759432.png" alt="PyCharm中创建项目第一步"></p><p>step2：</p><p><img src="/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/image-20230523230409940.png" alt="PyCharm中创建项目第二步"></p><p>如果运行代码发现默认使用不是自己需要的anaconda环境的python解释器，则可以在 pycharm 中的 <code>file—&gt;settings—&gt;Projects—&gt;Python Interpreter(python解释器)</code> 中进行重新配置所需的python解释器的路径。</p><p><img src="/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/image-20230523231921111.png" alt="Pycharm中重新配置项目的python解释器"></p><p>给下载的项目设置合适的虚拟环境</p><p><img src="/windows%E4%B8%8BPytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/image-20230523233255984.png" alt="给下载的项目设置合适的虚拟环境"></p><ul><li>conda install 下载安装不了包时可以采用 pip install。</li></ul><p>如何下载pytorch低版本？</p><ul><li>下载命令和普通方式命令类似，在pytorch官网上查就行。<br><code>conda install pytorch==旧版本 torchvision==旧版本 torchaudio==旧版本 -c 下载通道【可以换成镜像通道】 </code> </li><li>当使用国内镜像源下载安装pytorch时，可以先使用 <code>conda search pytorch==版本 -c 镜像站通道</code> 来查看是否在该镜像站存在有该版本的pytorch包，然后再进行下一步去安装。</li></ul><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">import pytorch<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-string">&quot;hello world&quot;</span>)</span></span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>PyTorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AI</title>
    <link href="/2022/06/15/AI/"/>
    <url>/2022/06/15/AI/</url>
    
    <content type="html"><![CDATA[<p>特此说明：该笔记仅用于学习用途，不用作任何商业用途！</p><h1 id="Machine-Learning"><a href="#Machine-Learning" class="headerlink" title="Machine Learning"></a>Machine Learning</h1><h2 id="机器学习概念"><a href="#机器学习概念" class="headerlink" title="机器学习概念"></a>机器学习概念</h2><ul><li><p>training set：训练集。用于训练机器学习算法的模型。</p></li><li><p>x：input varible。输入变量，也称为输入特征。</p></li><li><p>y：output varible。输出变量。</p></li><li><p>m：训练集样本个数。</p></li><li><p>n：输入的特征属性个数。（对于一个输入样本具有的feature数）</p></li><li><p>($ x^(i) $, $ y^(i) $)：表示第 i 个训练样本。。注意 i 表示索引而不是求幂运算。</p></li><li><p>$ \hat{y} $：yhat，估计值，输入到模型得到的输出。区别于 $ y $ ：真实值，指训练集样本的真实输出。</p></li><li><p>generalization：泛化能力。指的是模型适应新数据的能力。</p></li></ul><br><h2 id="Learning-algorithms（学习算法）"><a href="#Learning-algorithms（学习算法）" class="headerlink" title="Learning algorithms（学习算法）"></a>Learning algorithms（学习算法）</h2><ul><li><p>Supervised learning（监督学习）——现如今社会和工业界最常用（99%？）。</p><ul><li><p>definition: learns from being given “right answers”</p></li><li><p>监督学习的本质：找出输入 x 到输出 y 的最佳映射关系。</p></li><li><p>监督学习应用：</p><p><img src="/AI/image-20220801101315800-16619393822671.png" alt="监督学习举例"></p></li><li><p>使用监督学习算法的两类常见问题：<strong>回归</strong>问题（<strong>regression</strong>）和<strong>分类</strong>问题（<strong>classification</strong>）。</p><ul><li>回归问题：给定有限的数据集（离散点），通过监督学习算法，得到拟合这些离散数据点的最佳函数，即得到了一条最佳拟合曲线，从而实现对其他非数据集中的数据进行估计和预测。总结的说：回归问题是将输入经过回归模型最终预测为一个特定的值作为输出，而回归算法的目的就是为了获取一个最优的回归模型</li><li>分类问题：predict categories(class)。</li></ul><p>回归问题和分类问题的区别在于：回归问题要解决的是一段<strong>连续区间上任意点的预测</strong>，换句话说<strong>回归问题的输出的范围为一个无限的集合（数的区间）</strong>，而分类问题是对<strong>离散结果的预测，区分不同的类别</strong>，<strong>输出结果的范围是一个由有限多种可能组成的集合</strong>，例如区分猫狗兔，判断是否得病，是否为垃圾邮件等确定的离散结果。</p></li></ul></li><li><p>Unsupervised learning（无监督学习）</p><p><img src="/AI/image-20220801220943545-16619393822682.png" alt="监督学习和无监督学习的比较"></p><p>​图：监督学习和无监督学习的比较</p></li></ul><p>分析：如上图所示，左边为监督学习分类算法，对于输出结果都打上了对应的标签（如图中的⭕和×），即所谓的“right answers”，监督学习分类算法的目的是根据已有数据集输入特征（可以有多个输入，对应多个特征，例如上图中有两个输入：age和 tumor size）和对应输出（right answer），找出最佳分类曲线，从而实现对新样本的分类预测。右边为无监督学习示意图，可见输出没有标签，没有对输出划定明确的分类结果，无监督学习的目的是让算法自动的去寻找数据间的结构和关系，主动发现数据间一些有意思的相互联系。例如上面的聚类算法（clustering）发现上面的样本数据可以分为两大类。聚类算法有意思的应用：在众多新闻中聚类找出某个关键词或者某个相关话题提到的相关文章，或者将一些庞杂无体系的大量数据进行筛选、分组管理。聚类算法是自主的判断并将数据划分为不同的聚类，而不需要我们人为提供关键词或者具体的分类标准和结果。</p><p>监督学习和非监督学习的对比总结：</p><table><thead><tr><th align="center"></th><th align="center">监督学习</th><th align="center">无监督学习</th></tr></thead><tbody><tr><td align="center">输入</td><td align="center">可以有多个输入特征</td><td align="center">可以有多个输入特征</td></tr><tr><td align="center">输出</td><td align="center">有输出，输出有label，即有所谓的 right answers。</td><td align="center">没有明确的输出，通过算法自主确定输出。</td></tr><tr><td align="center">作用</td><td align="center">对不是数据集中的新的数据进行分类或输出预测</td><td align="center">将数据分组成不同的类别（聚类），区别于监督学习，这些类别是我们事先并不知道的。</td></tr><tr><td align="center">代表算法</td><td align="center">回归算法，分类算法</td><td align="center">聚类算法，异常检测算法，降维压缩算法</td></tr><tr><td align="center">场景</td><td align="center">患者是否患癌症的预测，邮件是否为垃圾邮件。</td><td align="center">Google新闻等媒体通过你的浏览喜好聚类所有你可能感兴趣的其他内容呈现在你眼前。</td></tr></tbody></table><ul><li>Reinforcement learning（强化学习）</li></ul><p><img src="/AI/image-20220801100309828-16619393822683.png" alt="image-20220801100309828"></p><p>当Andrew拿出锤子的那刻属实是蚌埠住了，哈哈哈哈</p><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p>$f_{w,b} &#x3D; wx + b$  该公式也常简写为：$f &#x3D; wx + b$ </p><p>其中：w，b称为模型参数（parameters），有时也称为系数（coefficients）或者权重（weights）</p><h2 id="损失函数（loss-function）"><a href="#损失函数（loss-function）" class="headerlink" title="损失函数（loss function）"></a>损失函数（loss function）</h2><p><img src="/AI/image-20220802100736808-16619393822686.png" alt="image-20220802100736808"></p><p>说明：</p><ol><li><p><strong>损失函数的自变量是模型参数</strong>，而不是训练样本。</p></li><li><p>平方误差损失函数：在线性回归问题中用的最多。</p></li><li><p>本质上是求模型估计值和实际样本输出值之间的误差，来评价模型的好坏，而改善模型的方向就是使得损失函数的值越小越好。即估计和真值之间误差越小越好。</p></li><li><p>误差平方的目的是防止正负误差抵消从而使得误差减小；</p><p>除以 m 的目的是为了求误差的平均，防止由于样本量的不断增加导致误差不断增大。</p><p>除以 2 的目的是为了后面求改损失函数的导数时方便与平方消掉，不影响作为误差的衡量。</p></li></ol><p><img src="/AI/image-20220802101035423-16619393822684.png" alt="image-20220802101035423"></p><p>线性回归问题的思路：</p><p>目的是为了得到一个模型。模型本身具有可调整的模型参数，我们首先确定评价模型好坏的损失函数，然后以使得损失函数最小为目标不断调整模型参数从而得到最优模型。 </p><h2 id="梯度下降算法（Gradient-Descent）"><a href="#梯度下降算法（Gradient-Descent）" class="headerlink" title="梯度下降算法（Gradient Descent）"></a>梯度下降算法（Gradient Descent）</h2><p>脑子中通过人最快下山情景来理解梯度下降算法。</p><ol><li><p>梯度下降算法的目标是自动的不断调整模型参数使得损失函数<strong>最快</strong>达到最小（局部最小，和初始值设置有关）。</p></li><li><p>梯度下降算法不仅对线性回归有效，同样的也可用于其他各种带有多参数的损失函数，例如 $J(w1,w2,w3,…,wn,b)$</p></li><li><p>线性回归问题的损失函数为一个U型或者碗状图，而对于其他更为复杂的损失函数可能存在多个局部极小值点，这时候对梯度下降算法给予不同的模型参数初始值，可能会最终收敛到不同的极小值点处。这点需要注意！</p></li></ol><p>梯度下降算法数学表达式</p><p><img src="/AI/image-20220802114501848-16619393822685.png" alt="梯度下降算法"></p><p>说明：</p><ol><li><p>Alpha：学习率（learning rate），一般位于区间 (0, 1)，学习率总是正数，例如 0.001。可以理解为下山的步子大小。</p><p>问：如何正确选择适当的学习率？</p><p>答：如果学习率太小，那么梯度下降至接近 loss function 最小值的速度会很慢。</p><p>​   如果学习率过大，梯度下降在接近 loss function 最小值点处会过冲（overshoot），无法收敛至最小值点，甚至会发散。</p></li><li><p>梯度下降算法就是循环运行梯度下降表达式（即例如上图中左上角的两个公式），对w, b 不断进行更新，从而最快的获得最佳模型参数。 </p><p>注意上图下方两种参数更新方式，<strong>正确的是位于左边的所有模型参数同时更新。</strong>注意观察左右两边的 tmp_b 更新的结果是不同的，右边由于先更新了 w，而后将新计算出来的 w 值代入计算 b 的更新，从而没有达到参数同时更新的效果。</p></li><li><p>在越接近局部最小值的过程中，偏导数将变得越小，即梯度越小（斜率越小），而此时对于固定学习率而言，整个梯度下降算法在逐渐接近局部最小值的过程中下降的幅度也会变得越来越慢。这也比较符合我们的直觉，在接近目标的时候变得细致谨慎一些（梯度小，斜率小，到达最小值时的导数为0，即斜率为0），而远离目标的时候需要幅度大一些（梯度大，斜率大）。</p><p>这里想要说明的是<strong>即使保证学习率不变</strong>，导数部分也会根据当前距离损失函数局部最小值的远近进行动态调整，可以实现最终到达极小值点的目标。</p></li><li><p>如果某个参数初始值恰巧使得loss function（J）到达局部最小值（极小值），那么梯度下降算法不会再让这个参数发生改变。改变学习率也无济于事。</p></li></ol><p>凸函数：只会存在一个最小值，不会存在多个极小值点，该最小值也就是全局最小值点。</p><p>对于线性回归问题，一般选用平方误差函数作为loss function，他的图像是一个碗状，是凸函数，只存在一个最小值，也就是全局最小值。</p><p>处理线性回归问题采用的是 batch gradient</p><p>特征缩放可以加速梯度下降至收敛的速度。</p><p>梯度下降的目的是找出使得loss function J最小的w和b的值。</p><p>通过看学习曲线learning curve 来判断梯度下降是否收敛。如果曲线渐趋平缓，那么代表收敛。如果曲线先降后升，代表模型发散，或者为学习率太大，或者代码出错等情况。</p><p>学习曲线：横坐标为迭代次数，表示运行完几次同步更新模型参数的梯度下降算法；纵坐标为loss function J的值（例如平方误差）。</p><h2 id="监督学习——分类问题-classcification"><a href="#监督学习——分类问题-classcification" class="headerlink" title="监督学习——分类问题(classcification)"></a>监督学习——分类问题(classcification)</h2><p>引言：在监督学习中，有两类问题：1. 回归问题(线性回归，多元线性回归)；2. 分类问题。</p><p>而本小节讨论的是如何解决分类问题。分类问题区别于回归问题在于其输出结果<strong>有限</strong>，<strong>离散</strong>。</p><h3 id="Logistic-Regression-逻辑回归"><a href="#Logistic-Regression-逻辑回归" class="headerlink" title="Logistic Regression(逻辑回归)"></a>Logistic Regression(逻辑回归)</h3><p>逻辑回归算法虽然带有回归两个字，但是逻辑回归是一种解决分类问题的算法，并不是解决回归问题。</p><p><img src="/AI/image-20220814212914680-16619393822687.png" alt="逻辑回归"></p><p>如上图所示，首先对于以上二分类问题是属于分类问题，逻辑回归算法处理。</p><p>逻辑回归本质上是由已有的数据集，拟合一条如上图红色部分的曲线，而不是线性回归中的直线拟合。</p><img src="AI/image-20220814213145968-16619393822688.png" alt="image-20220814213145968" style="zoom:80%;" /><p>对于拟合曲线一般采用sigmoid函数，也称为logistic函数。</p><p>sigmoid函数特点：如上图中的g(z)所示，函数范围为(0，1)，当 z &#x3D; 0 时，g（z）&#x3D; 0.5。</p><p><img src="/AI/image-20220814213441012-166193938226812.png" alt="logistic 算法"></p><p>上图展示的是对于先前提出的肿瘤二分类问题的logistic算法具体实现原理。本质上就是将sigmoid函数的自变量z替换成输入特征即可。</p><p>对于输出是介于(0,1)区间的小数，<strong>这里对计算输出的结果正确的理解是：判断结果为 0 或 1 的概率。</strong></p><h3 id="逻辑回归算法核心公式"><a href="#逻辑回归算法核心公式" class="headerlink" title="逻辑回归算法核心公式"></a>逻辑回归算法核心公式</h3><img src="AI/image-20220814214009626-16619393822689.png" alt="image-20220814214009626" style="zoom:80%;" /><h3 id="二分类问题的-loss-function"><a href="#二分类问题的-loss-function" class="headerlink" title="二分类问题的 loss function"></a>二分类问题的 loss function</h3><p>（不能再用线性回归中的平方误差函数作为分类问题的损失函数(J)，应当进行改写）</p><p>之所以要改的原因是因为如果接着使用平方误差函数做为分类问题的loss function的话，那么他的曲线为此起彼伏的曲线，拥有很多个极小值点，那么就不方便使用梯度下降算法求最优的模型参数。</p><img src="AI/image-20220814221434188-166193938226810.png" alt="image-20220814221434188" style="zoom:80%;" /><p>如上图所示为二分类问题中单个输入的 loss function，进一步进行整合简化如下：</p><p><img src="/AI/image-20220814221542879-166193938226811.png" alt="image-20220814221542879"></p><p>综上所述：二分类问题的logistic算法的loss function（J(w,b)）为：（在上面的基础上再求个平均）</p><p><img src="/AI/image-20220814222110164-166193938226813.png" alt="image-20220814222110164"></p><p>逻辑回归算法中的梯度下降算法：</p><p><img src="/AI/image-20220814223622659-166193938226814.png" alt="image-20220814223622659"></p><p>注意：</p><ol><li>逻辑回归和之前的线性回归问题的梯度下降算法的<strong>偏导部分</strong>形式一样，但是要注意虽然形式一样，但是函数定义不一样，一个是线性函数，一个是sigmoid函数。</li><li>对于同一样本的不同取值范围的特征，可以采用特征缩放的手段使得各个特征均处于相同或者类似区间范围内，这样的<strong>特征缩放做法可以加快梯度下降算法的收敛</strong>。</li></ol><h3 id="过拟合问题-overfitting"><a href="#过拟合问题-overfitting" class="headerlink" title="过拟合问题(overfitting)"></a>过拟合问题(overfitting)</h3><p>采用正则化方法可以最大程度的减少过拟合问题。</p><p>回归问题的拟合问题</p><p><img src="/AI/image-20220816142718848-166193938226815.png" alt="image-20220816142718848"></p><p>分类问题的决策边界选择问题</p><p><img src="/AI/image-20220816143518592-166193938226816.png" alt="image-20220816143518592"></p><p>分析（综合上面两张图）：</p><ol><li>最左边图欠拟合（也称为：high bias），拟合效果不佳；</li><li>最右边图为用更高阶的多项式进行拟合出现过拟合现象，虽然拟合曲线很好的匹配了输入测试集样本，但是可以看到该曲线没有很好的泛化能力，并不能很好的描述样本的趋势，若换一个样本集，那么其适应能力大大降低。也称为 high variance。</li><li>中间图认为模型 just right，具有很好的泛化能力（generalization）。</li></ol><p>解决过拟合问题的方法：</p><ul><li><p>方法1：增加更多的训练集样本用于模型训练。</p></li><li><p>方法2：对所有样本进行适当的特征选择，而不是利用每个样本所有的特征进行训练，选择最能影响当前输出的几个关键的特征进行模型训练。</p><blockquote><p>往往模型参数越多，越容易导致过拟合。所以这种方式的思路就是通过减少特征，进而减少模型参数 w1, w2, …，达到防止过拟合的目的。</p></blockquote></li><li><p>方法3：<strong>正则化方法（Regularization）。推荐</strong>，做常用的方式。相对于方法2而言，它并不是对特征进行筛选，而是通过控制调整 w1, w2, …, wn 的值来降低不必要特征对模型的影响。</p><blockquote><p>当然，一般只会选择减小模型参数 w 的影响而不会选择动 b 参数，理论上正则化 b 对模型整体效果不会由很大的影响，所以一般只会正则化 w。</p></blockquote></li></ul><h3 id="正则化（Regularization）"><a href="#正则化（Regularization）" class="headerlink" title="正则化（Regularization）"></a>正则化（Regularization）</h3><p>目的：解决模型过拟合问题</p><p><img src="/AI/image-20220816151316682-166193938226817.png" alt="image-20220816151316682"></p><p>说明：</p><ol><li><p>以上 J(w, b) 损失函数的表达式是在解决回归问题的平方误差函数的基础上增加了一个正则化项 （regularization term）。</p><blockquote><ul><li>除以 2m 是为了使得无论增加多少样本，lamda依然能够起到相同的正则化作用。</li><li>取平方是防止 w 之间正负抵消，这和平方误差的思想类似。</li><li>多除以了一个 2 是为了求导的时候抵消平方下来的 2。</li></ul></blockquote></li><li><p>lamda 的确定问题。</p><p>考虑两种极端情况：</p><ul><li><p>若 lamda 太小，这里直接将其设置为 0，那么此时相当于正则化项不起作用，原来的高阶函数拟合样本出现过拟合现象。如下图所示。</p><img src="AI 笔记/image-20220816151819438-166193938226818.png" alt="image-20220816151819438" style="zoom:50%;" /></li><li><p>若 lamda 太大，这里认为它趋于无穷，那么此时正则化项在损失函数中起到很大权重，认为损失函数约等于正则化项，采用梯度下降算法更新模型参数使得损失函数趋于局部最小，即：使得正则化项最小，因为 lamda 很大，那么就会导致所有模型参数 w1, w2,… 变得非常小才可能使得 loss function 最小，这里取极端情况：所有的 w1, w2, …等于0，那么此时 $f_{w, b} &#x3D; b$，为一条平行于x轴的直线，于是此时变成欠拟合（high bais）。如下图所示。</p><img src="AI/image-20220816152416125-166193938226819.png" alt="image-20220816152416125" style="zoom:50%;" /></li></ul></li></ol><p>加入正则化项后的梯度下降算法：（正则化<strong>线性回归问题</strong>，防止过拟合）</p><p><img src="/AI/image-20220816153211078-166193938226920.png" alt="image-20220816153211078"></p><p>说明：</p><ol><li>加入正则化项只是对 wj 的更新表达式多了一项，而 b 的更新表达式不变。</li></ol><p>换个角度深入理解增加正则化项的目的</p><p><img src="/AI/image-20220816154055313-166193938226921.png" alt="image-20220816154055313"></p><p>分析：对于上图梯度下降算法中不断更新 wj  和 b，因为加入正则化项对 b 的梯度下降表达式不受影响，这里讨论 wj，如图可以看到这里对 wj 的表达式进行改写得到最下面的手写表达式 wj。可以看到表达式的后半部分和不加入正则化项的梯度下降表达式一样，*<em>只是前半部分由原来的 wj 变为了 wj(1-a</em>lamda&#x2F;m)**。</p><p>​最右边对a，lamda，m 进行了假设赋值，可以看到这样的赋值使得 wj 在每次执行梯度下降算法的时候都将自己乘以一个小于1的数进行了缩小，于是这里就可以看出<strong>正则化的根本目的就是实现对模型参数 wj 的缩小，减小各个模型参数对模型的过分影响，从而防止过拟合。</strong></p><p>逻辑回归问题（分类问题）的正则化梯度下降算法</p><p><img src="/AI/image-20220816155741815-166193938226922.png" alt="image-20220816155741815"></p><p>分析：可以看出来逻辑回归问题的梯度下降算法表达式和线性回归问题的形式上是相同的，只是注意 $f_{w,b}$ 的定义不同。线性回归问题是线性多项式，而逻辑回归问题（分类问题）是 sigmoid 函数。</p><h2 id="神经网络（neural-networks、deep-learning）"><a href="#神经网络（neural-networks、deep-learning）" class="headerlink" title="神经网络（neural networks、deep learning）"></a>神经网络（neural networks、deep learning）</h2><p>本章学习内容</p><ol><li>神经网络：推理（Inference，Prediction） &amp; 如何训练</li><li>Practical advice for building machine learning systems</li><li>Decision Trees（决策树）</li></ol><p><strong>&#x3D;&#x3D;创建神经网络的思路&#x3D;&#x3D;<strong>：将原来传统的解决</strong>逻辑回归问题</strong>的算法封装在一个个的神经元里，然后将它们连接起来。</p><p>神经网络</p><p><img src="/AI/image-20220816162328358-166193938226923.png" alt="image-20220816162328358"></p><p>为什么神经网络（深度学习）现在很火，或者说它与其他传统的机器学习算法的优势在哪里？</p><p><img src="/AI/image-20220816162408082-166193938226924.png" alt="image-20220816162408082"></p><p>分析：通过上面这张图可以看出来用神经网络对样本进行训练的表现（表现指的是训练误差等等评判模型性能的参数）要比传统的机器学习算法（例如线性回归算法和逻辑回归算法）要好很多，而且随着数据量的增加其性能变得更加优异。同时，随着神经网络的规模增大，它的训练效果也会变得更加优秀。</p><p>神经网络结构</p><p><img src="/AI/image-20220816180534814-166193938226925.png" alt="image-20220816180534814"></p><p>理解：</p><ol><li>每一个神经元都是一个 logistic function，输出一个 (0, 1) 区间的小数，可以理解为概率。</li><li><strong>每一个神经元都会计算出一个结果</strong>。每一层有多少个神经元，就会输出多少个这样的值，以向量 a 的形式存储起来传递给下一层。</li><li>神经网络分为<strong>输入层，隐藏层和输出层</strong>。有时也认为输入层不算神经网络的层级。</li><li>上图神经元之间采用全连接的方式连接前后层级。</li><li>上标表示所在层级，下标表示属于该层级的神经元标号。具体上下标说明见下图所示。</li></ol><p><img src="/AI/image-20220816180124692-166193938226926.png" alt="上下标定义总结"></p><p>​注意：我们也时常称神经元中的算法函数 sigmoid 或者其他函数为<strong>激活函数</strong>（activation function）。</p><p>​当然激活函数不只有 sigmoid 函数。</p><ol start="6"><li><p><strong>从左到右</strong>的顺序不断激活每个神经元进行计算称为<strong>前向传播</strong>（forward propagation）。</p><p><strong>从右向左</strong>进行模型参数学习的过程称为<strong>反向传播算法</strong>（back propagation）。</p></li><li><p>注意一个细节，一般的神经网络架构在<strong>接近输出层的时候神经元个数在逐渐减少</strong>。</p></li></ol><p>Tensorflow 中的数据存储形式：</p><img src="AI/image-20220816183408504-166193938226927.png" alt="image-20220816183408504" style="zoom: 50%;" /><p>分析：</p><ol><li>Tensorflow 中调用 python 中的 numpy 库生成矩阵（行向量，列向量，多维向量）来存储数据。</li><li>注意 Tensorflow 和 numpy 矩阵存储数据的方式不太一样，但是中间可以相互转换。</li><li>注意：如上图所示，<strong>在 Tensorflow 中使用前两者方式存储数据</strong>，即：使用<strong>两个中括号</strong>来表示将数据存储在一个二维矩阵中；而最下面这种方式并不表示将数据存储在矩阵中，而是以一个列表一维的形式存储数据。</li></ol><p>约定俗成：算法中使用到的大写字母认为是矩阵，而小写字母为向量或者标量。</p><p>AGI：artificial general intelligence（通用人工智能）</p><p><img src="/AI/image-20220816203104544-166193938226928.png" alt="image-20220816203104544"></p><p>该图的理解：不要因为在 ANI（狭义人工智能）上的成就加上媒体在这方面的炒作就认为目前的 AI 已经很成熟，实际上，在我们目前看得到的 ANI 的应用只是属于 AI 的一个子类，对于通向完全智能的 AGI 仍然还有很长的路要走。</p><p><strong>基于Tensorflow搭建一个神经网络模型</strong></p><p><img src="/AI/image-20220816225155327-166193938226929.png" alt="搭建一个神经网络模型"></p><p>名词解释：Sequential：连续排列，activation：激活函数。Dence：该函数表示构建一层神经网络。units：神经元个数。</p><p><strong>单个网络层上的前向传播</strong></p><p><img src="/AI/image-20220816225635333-166193938226931.png" alt="image-20220816225635333"></p><p>注意：变量下标表示该层级对应的参数序号，上标表示对应的神经网络层级。</p><p><strong>单个网络层上的前向传播的具体底层python代码的实现</strong></p><p><img src="/AI/image-20220816230116416-166193938227057.png" alt="image-20220816230116416"></p><p>说明：</p><ol><li>注意该实现中的多项式乘法运算没有采用矩阵乘法运算，是利用for循环逐一计算各值，因此该算法的执行效率是很低的，只是帮助原理层面的理解，实际开发代码中不会采用这种方式。</li><li>简单了解一下这个机制就好，不需要重点掌握！只是为了方便我们对底层计算的理解。具体的还是应当掌握下面会提到的利用矩阵的乘法运算来进行前向传播（模型推理）。</li></ol><h3 id="矩阵乘法的理解"><a href="#矩阵乘法的理解" class="headerlink" title="矩阵乘法的理解"></a>矩阵乘法的理解</h3><p>因为像 GPU 和部分 CPU 拥有强大的矩阵乘法计算能力，而利用矩阵乘法计算的运行速度远远快于用普通for循环进行多项式计算的算法，这才使得深度学习得以迅速的发展。</p><p><img src="/AI/image-20220816222244332-166193938226930.png" alt="image-20220816222244332"></p><p>上图说明：两个列向量点乘（图的左边）等价于其中一个列向量的转置（即变为行向量）与另一个列向量的矩阵乘法运算。</p><p>注意：至少在深度学习中，鼓励对矩阵的理解为矩阵是由多个有含义的列向量构成的。</p><img src="AI/image-20220816223109918-166193938226932.png" alt="image-20220816223109918" style="zoom:50%;" /><h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><p><img src="/AI/image-20220816224755396-166193938226933.png" alt="基于矩阵乘法的单层神经网络前向传播实现"></p><p>说明：</p><ol><li>上图所示是基于<strong>矩阵乘法</strong>的<strong>单层</strong>神经网络<strong>前向传播</strong>实现。即已知模型参数，进行前向传播，也称为模型推理。</li><li>np.matmul 指的是调用 numpy 中的矩阵乘法运算。</li></ol><p><strong>模型训练步骤：（分3步走）</strong></p><p><img src="/AI/image-20220817150143427-166193938226938.png" alt="image-20220817150143427"></p><p>下面是具体的训练神经网络的三个步骤的 Tensorflow 代码：</p><p><strong>一、步骤1：确定模型</strong></p><p><img src="/AI/image-20220817150414893-166193938226934.png" alt="image-20220817150414893"></p><p>分析：该步骤搭建好神经网络的结构。</p><p>二、步骤2：确定 Loss function or Cost function（即确定模型误差函数，衡量模型的函数、待优化的目标）</p><p><img src="/AI/image-20220817151306431-166193938226935.png" alt="image-20220817151306431"></p><p>说明：对于二元分类问题（结果要么为 0 要么为 1），tensorflow 中采用二元交叉熵函数（Binary Crossentropy）作为神经网络的 loss function。对于回归问题，采用平方误差函数（Mean Squared Error）作为 loss function。</p><p>三、步骤3：采用<strong>梯度下降算法</strong>使 loss function 最小，使得模型参数最优。</p><p><img src="/AI/image-20220817152255001-166193938226936.png" alt="image-20220817152255001"></p><p>说明：在 tensorflow 中直接调用 fit 函数即可实现神经网络的<strong>反向传播算法</strong>，这种算法类似解决传统的回归问题而后分类问题的梯度下降算法。epochs 为设置模型训练的迭代次数。</p><h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><h4 id="为什么每个神经元需要激活函数"><a href="#为什么每个神经元需要激活函数" class="headerlink" title="为什么每个神经元需要激活函数"></a>为什么每个神经元需要激活函数</h4><p>隐藏层不要使用线性激活函数（相当于没用函数）。</p><h4 id="激活函数的种类"><a href="#激活函数的种类" class="headerlink" title="激活函数的种类"></a>激活函数的种类</h4><p>目前深度学习中常用激活函数如下：</p><p><img src="/AI/image-20220817153354437.png" alt="image-20220817153354437"></p><p>常用激活函数：</p><ol><li><p>线性激活函数：g(z) &#x3D; z；当使用线性激活函数时，有时人们也会说<strong>没有使用激活函数</strong>。</p><p>因为 **<code>a = g(wx + b) = wx + b</code>**，相当于没有使用 g 这个函数。</p></li><li><p>Sigmoid 函数，之前处理分类问题时候曾提到过。</p></li><li><p>ReLU 函数，<code>g(z) = max(0, z)</code>，当 x &lt; 0 时，g(z) &#x3D; 0；当 x &gt;&#x3D; 0 时，g(z) &#x3D; z。注意和线性激活函数不同。</p></li></ol><h4 id="激活函数的选择"><a href="#激活函数的选择" class="headerlink" title="激活函数的选择"></a>激活函数的选择</h4><ol><li><p>对于<strong>输出层</strong>（output layer）</p><p><img src="/AI/image-20220817154401670.png" alt="image-20220817154401670"></p><ul><li>如果输出 y 是对应处理二值分类问题，输出层神经元采用 sigmoid 激活函数；</li><li>如果处理的是回归问题，例如股票跌涨幅度，输出 y 可正可负，则输出层神经元采用 Linear 激活函数；</li><li>如果处理的是回归问题，但是输出 y 要求是大于 0 的场景，则输出层神经元采用 ReLU 函数。</li></ul></li><li><p>对于<strong>隐藏层</strong>（hidden layer）</p><p>一般推荐只使用 <strong>ReLU 激活函数</strong>，是目前隐藏层最常用的激活函数（吴恩达教授推荐）。虽然最近几年会有其他一些激活函数如 tanh 激活函数，Leaky ReLU 函数出现，但是这些都只在一些特定的网络中有些许的优势。对于目前一般的应用，选用ReLU 函数足够。</p><p>隐藏层选择 ReLU 的理由：</p><ol><li>ReLU 函数较 Sigmoid 函数等其他函数形式简单，运算速度快。</li><li>在进行梯度下降算法的时候需要对激活函数本身求导，ReLU 函数求导方便，且它的函数曲线很陡峭，不像 sigmoid 函数两边很平缓，下降速度慢。因此 ReLU 激活函数的梯度下降过程更加的快速和高效。</li></ol></li></ol><p>激活函数选择&amp;模型搭建代码举例：</p><p><img src="/AI/image-20220817160917555-166193938226940.png" alt="image-20220817160917555"></p><h3 id="多分类问题（multiclass-classification）"><a href="#多分类问题（multiclass-classification）" class="headerlink" title="多分类问题（multiclass classification）"></a>多分类问题（multiclass classification）</h3><p>结果不再是0 或 1的二分类问题。例如一张图片中有很多物体，有很多label，不同分类。</p><p><img src="/AI/image-20220817165407108.png" alt="image-20220817165407108"></p><p><img src="/AI/image-20220825094512491.png" alt="image-20220825094512491"></p><p>多分类问题的神经网络模型（举例说明而已，实际上根据实际问题的不同，模型也不同）</p><p><img src="/AI/image-20220825094618162.png" alt="image-20220825094618162"></p><p>分析：可以看到输出层有三个神经元，每个神经元的输出值分别代表的是有无车，有无大巴，有无行人的概率。</p><p>多分类问题采用 Softmax 算法，Softmax 算法是 二分类问题的 logistic 算法的推广。当如下图所示 N &#x3D; 2时，Softmax 算法退化为 logistic 算法。</p><p><img src="/AI/image-20220817170412882.png" alt="image-20220817170412882"></p><p>多分类问题的 Cost Function</p><p><img src="/AI/image-20220817171226025.png" alt="image-20220817171226025"></p><p>注意：</p><ol><li><p>loss function 指的是单一样本训练的误差，而 Cost function 指的是全体样本参与（全体模型参数参与）的平均训练误差。</p></li><li><p>对 -log 曲线用于 loss function 的理解：</p><p>首先是一个单调下降的曲线，纵坐标为 loss 误差，横坐标为：a，每个神经元中经过 softmax 激活函数算出来的结果，取值范围为(0, 1)。所以 a 的值越靠近 1，代表判断为该结果（标签）的概率越大，代表 loss 误差越小。</p></li></ol><p><img src="/AI/image-20220817172716638.png" alt="image-20220817172716638"></p><p>注意：Softmax 最后每个神经元的输出是<strong>用的不同的输入z，不是统一的 z，然后统一的表达式输出不同的结果</strong>，这一点一定要注意，这是与其他模型的区别！<strong>每个神经元的 z 的w，b模型参数是不同的</strong>，所以计算输出结果不同。</p><p><img src="/AI/image-20220817172729730.png" alt="image-20220817172729730"></p><p><strong>multi-label classification</strong>（用于图片）</p><p>对比一下 multi-label classification 和 multiclass classification：</p><p>multiclass classification针对的典型问题如手写识别，例如识别输入的0-9数字。那么对于一个人手写一个数字，最终输出判断的是0-9不同数字的概率，并最终根据这些概率认为输出的数字是最大概率的那个。所以multiclass classification 针对的场景是根据输入，判断唯一分类输出的情况。</p><p>multi-label classification针对的典型问题是图片。例如输入一张图片，同时需要判断这张图片上的不同特征，例如是否有猫，是否有狗，是否有人等等，相当于最终的输出带有不同label的特征信息。</p><h3 id="高级优化方法"><a href="#高级优化方法" class="headerlink" title="高级优化方法"></a>高级优化方法</h3><p>这里的高级优化方法指的是用于最小化 Cost Function 的一些优化方法。之前提到了我们最小化目标函数的方法采用梯度下降算法，而高级优化方法就是在此基础上对原来传统的梯度下降算法做出一些改进。<strong>优化方法的根本目的是加快模型训练的速度。</strong></p><p>需求：有时候我们希望 learning rate（学习率）大一点，这样梯度下降的速度会快一点；而有的时候我们希望学习率小一点，防止无法达到我们损失函数cost function的局部最小值而产生震荡。所以我们需要learning rate 可以自适应的动态调整，因此诞生出Adam算法，<strong>一种学习率自适应的梯度下降算法</strong>。</p><p><strong>Adam algorithm</strong></p><p><img src="/AI/image-20220825100111084.png" alt="image-20220825100111084"></p><p>首先，<strong>Adam算法并不是给全局的模型更新参数设置同一个学习率</strong>，而是<strong>不同的参数梯度下降表达式中设置不同的学习率</strong>（如上图所示）。因此若有 n 个模型更新参数，则 Adam 算法首先为他们设置 n 个不同的学习率，每个学习率各自做自适应的动态调整。</p><p><img src="/AI/image-20220825100037369.png" alt="image-20220825100037369"></p><p>其次，根据直觉理解 Adam 算法实现的原理，如上图所示，若发现前后计算的梯度值大致相同，即表示前后两次梯度下降的方向大体不变，此时认为前进方向没错，于是增大学习率，大踏步向前走；而若发现前后两次的梯度下降方向改变频繁，即认为出现震荡，于是减小学习率，小碎步使其收敛。</p><p><strong>TensorFlow中实现Adam算法</strong></p><p><img src="/AI/image-20220825100912849.png" alt="image-20220825100912849"></p><p>相比较之前的代码，只需要在 model.compile 中指明需要的 Adam 优化器即可，还需要设置初始学习率，而随后系统将采用 Adam 优化算法进行模型参数的最优化逼近。当然实际调试中可以修改初始学习率的值，来看看哪个初始值更能提高整个模型训练的效率。</p><blockquote><p>吴恩达教授建议：一般地，Adam算法要比传统的梯度下降算法对模型的训练速度更快。目前，Adam 算法在工业界中已经得到广泛的应用，尤其在神经网络的训练中，一般都建议采用Adam算法来进行模型训练。</p></blockquote><h3 id="其他的网络层类型"><a href="#其他的网络层类型" class="headerlink" title="其他的网络层类型"></a>其他的网络层类型</h3><p>之前学习的神经网络是一种 Dense Layer 结构，即密集型神经网络，它的隐藏层每个神经元的输出都包含了前一层的所有神经元的输入，是全连接的结构。如下图所示。</p><p><img src="/AI/image-20220825101855984.png" alt="image-20220825101855984"></p><p>另外的，有一种是卷积层结构，即卷积神经网络（CNN）。</p><p><img src="/AI/image-20220825102935325.png" alt="image-20220825102935325"></p><p>分析：区别于密集型层结构的神经网络结构，卷积神经网络的隐藏层中的每个神经源只获取前面部分神经元的输入，只获取部分信息。拿输入的是一张图片来说，卷积神经网络的每个神经元值只提取一张图片中的一部分区域的像素作为输入。这样的结构可以加快计算速度，同时减小了需要的训练数据，一定程度上也能防止过拟合。</p><p><strong>卷积神经网络的例子</strong>（注意这是一个一维的例子，而不是例如图像的二维的例子）</p><p>根据心电图电压波形来判断这个人是狗患有心脏病。其中x1，x2…x100 表示划分的100个时刻对应的电压。</p><p><img src="/AI/image-20220825103639197.png" alt="image-20220825103639197"></p><p>卷积层神经网络模型结构分析：</p><p>如上图所示，可以看到第一层卷积层由9个神经元构成，其中每个神经元分别只看前面10个时刻的电压（即只有前面10个时刻的电压值作为输入）。第二层卷积层由3个神经元构成，其中每个神经元只看前面5个神经元的计算结果（注意：可以有重叠）。最后输出层利用sigmoid函数将前级3个神经元的输入进行综合计算求出该病人患心脏病的概率。</p><p>&#x3D;&#x3D;<strong>可以修改卷积神经网络的层级结构、每层的神经元个数、每个神经元获得的前级神经元信息数量来改善网络模型。</strong>&#x3D;&#x3D;</p><h2 id="模型训练指导"><a href="#模型训练指导" class="headerlink" title="模型训练指导"></a>模型训练指导</h2><p>本章将学习到一些有效的模型训练方法和技巧，以及如何判断评估一个模型的好坏，以及当模型的结果很糟糕时，我们又如何发现问题，如何调整优化。</p><p>例如，如下图所示，当我们之前的房屋预测模型输出结果很差的话，我们如何排查问题，下一步如何做来提升改进模型，提升模型性能。</p><p><img src="/AI/image-20220825105424279.png" alt="image-20220825105424279"></p><h3 id="1-评估模型的好坏"><a href="#1-评估模型的好坏" class="headerlink" title="1. 评估模型的好坏"></a>1. 评估模型的好坏</h3><p>对于一维的线性回归问题，我们可以将拟合曲线画出来和数据进行比较直观的判断模型的好坏。但是若输入特征有很多，不再是一维的情况，那么就很难直观的将图形画出来看到反应模型好坏的图形。</p><p>因此更多的时候我们采用一种将模型划<strong>分为训练集和测试集</strong>，利用训练集训练，而利用测试集测试的方法来评估模型的好坏。</p><p><img src="/AI/image-20220825110943060.png" alt="image-20220825110943060"></p><p>上述将样本数据只划分为训练集和测试集的方式有时候并不能保证模型具有很好的泛化能力。更加稳妥的方式是将数据样本划分为测试集，验证集和测试集，利用测试集和验证集来选择模型，利用测试集来评判模型的好坏。</p><p><img src="/AI/image-20220825114743843.png" alt="image-20220825114743843"></p><ol><li><p>其中验证集也称为：validation set 或者 development set 或者 dev set，都表示验证集的意思。</p></li><li><p>在前面只划分训练集和测试集，是否有必要再在测试集中分一个验证集出来？</p><p>个人认为这是有必要的，如果不同模型训练好后来比较模型的好坏，只是看测试集误差，可能不同模型之间在计算该测试集误差时其中不同样本误差有大有小，其平均后在外界看来显得测试集误差很小，但是因为其中可能包含有些很大的样本误差，不能说明模型是好的。将测试集进一步划分相当于剖开更仔细地看内部的误差，这样更容易抓出其中大的误差点，更能放大的体现出模型的好坏。</p></li><li><p>个人理解：将数据样本多划分了一个验证集就好比多加了一门考试，这样通过测试集考一次，再通过验证集期末考再考一次，两次综合评价更能确保你是否真的掌握了知识，是否真的学会了。前面只划分训练集和测试集有点类似于一考定终生，有时候不一定能反映这个人的平均真实稳定水平。</p></li></ol><p>总结起来，一种最有效的模型选择或者模型参数选择的方式就是：先将所有数据样本划分为训练集，（交叉）验证集和测试集。在初步选择模型架构或者训练模型参数的时候只用训练集和验证集。选择的不同的模型分别用训练集进行训练，获得模型参数后分别利用验证集进行验证，计算各种模型的验证集误差，挑选出验证集误差最小的模型作为选择的模型，然后再将该模型及其模型参数用测试集测试，计算测试集误差，从而综合评估模型的好坏（泛化能力）。</p><hr><h1 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h1><p>课程——同济子豪兄的课程。</p><p>推荐 CS231N 课程</p><h2 id="第一课"><a href="#第一课" class="headerlink" title="第一课"></a>第一课</h2><h3 id="计算机视觉解决的3大问题——分类，检测，分割"><a href="#计算机视觉解决的3大问题——分类，检测，分割" class="headerlink" title="计算机视觉解决的3大问题——分类，检测，分割"></a>计算机视觉解决的3大问题——分类，检测，分割</h3><p><img src="/AI/image-20220818152444583-1661939503311115.png" alt="image-20220818152444583"></p><ul><li><p>分类（Classification）：可以是二分类，可以是多分类。输入图像，输出判断图像所属的类别。</p></li><li><p>检测（Object Detection）：利用矩形框将目标框出来。</p><blockquote><p>其中矩形框只需要两个参数即可画出，矩形框左上角和右下角两点的坐标。</p></blockquote></li><li><p>分割（Segmentation）：如果只是用矩形框标出目标对象，在矩形框内会有很多包含如背景等很多其他的冗余信息，在某些场景下是我们所不需要的，于是需要采用分割的算法，如上图中最右边图所示，分割算法将目标标出。分割技术在无人驾驶领域是非常重要的。</p></li></ul><p>其中，三种问题中，<strong>分割问题最难</strong>。</p><ul><li><p>分类问题是对整个图像进行分析。</p></li><li><p>目标检测问题是对定位信息进行分析。</p></li><li><p>分割问题是对图片像素粒度进行分析。</p></li></ul><p><strong>进一步细分</strong></p><p><img src="/AI/image-20220818153921778-1661939503311116.png" alt="image-20220818153921778"></p><p>说明：上图展示的是计算机视觉解决的不同问题分类。</p><ol><li>注意目标定位（Object Localization）和目标检测（Object Recognition）的区别。如上图中第一行的后两张图对比。</li><li>注意语义分割（Semantic Segmentation）和 实例分割（Instance Segmentation）的区别。<ul><li>语义分割是将一幅图上判断为同一类别的物体用同样的颜色表示出来，例如上图中第二行的第一张图，所有的羊被认为是同样的一个整体，认为是同一个物体。</li><li>实例分割是将一幅图上的不同实例（不同的个体对象）全部分割区分开来。例如上图中第二行的第二张图，虽然都为羊，但是是不同实例（对象），于是将其每个实例分割区分开来。这在自动驾驶领域十分重要。</li></ul></li><li>上图中第二行的最后一张图为关键点检测。提取目标对象关键点信息，例如关节，即可获取其姿态和运动状态等。有望应用于当前的动漫动作捕捉行业以及例如篮球等运动分解、教学领域。</li></ol><p><strong>分类问题</strong>：判断一幅图中目标对象所属的种类。（一般这类问题中图片中只会出现一个对象，例如手写输入文字识别）</p><p><img src="/AI/image-20220818155336123-1661939503311117.png" alt="image-20220818155336123"></p><p><strong>目标检测问题</strong>：用画矩形框的形式框出一幅图上不同的物体对象。</p><img src="AI/image-20220818155245104-1661939503311118.png" alt="image-20220818155245104" style="zoom: 80%;" /><p><strong>语义分割</strong>：像素级的检测分割。将判断为同一个label，同一个类别的物体对象在像素级尺度上分割为一类，用相同的颜色表示。注意此时不区分不同的实例。</p><p><img src="/AI/image-20220818155359103-1661939503311119.png" alt="image-20220818155359103"></p><p><strong>实例分割</strong>：像素级的分割。将一幅图上的不同实例都在像素级尺度上单独分割出来。</p><p><img src="/AI/image-20220818155412509-1661939503311120.png" alt="image-20220818155412509"></p><p><strong>关键点检测</strong>：例如检测人体的各关节。</p><p><img src="/AI/image-20220818155421399-1661939503311121.png" alt="image-20220818155421399"></p><h3 id="计算机视觉发展前沿"><a href="#计算机视觉发展前沿" class="headerlink" title="计算机视觉发展前沿"></a>计算机视觉发展前沿</h3><p>深度学习-计算机视觉</p><p>深度学习三驾马车：算力（硬件），数据（特别是海量的经过标注好的数据，例如 ImageNet 图像数据集），算法（如何高效的训练一个很深的神经网络，防止其过拟合）</p><p>ImageNet：由斯坦福大学华人科学家李飞飞教授提出。有几百万张经过标注好的分类图片。</p><p>下图是 ImageNet 举办的<strong>图像分类</strong>比赛，2017年停止举办。</p><p><img src="/AI/image-20220818170040695-1661939503311122.png" alt="image-20220818170040695"></p><p>分析图片：横坐标为举办比赛的年份以及获得冠军队伍采用的神经网络框架，纵坐标为图像分类的错误率。</p><p>重要关键时间点：</p><ol><li>2012年 AlexNet 横空出世，首次在图像分89中使用深度学习中的卷积神经网络，且识别图像错误率大幅度下降。</li><li>2014年 Google 推出 GoogleNet。</li><li>2015年由中科院提出的 ResNet 图像分类识别错误率首次低于人类，首次超过人类（人类的错误识别率入如图所示在 5%-10%）。错误率在 5% 以内。于是在2017年结束后，人们认为图像分类领域已经达到很高的程度，于是停止了该图像分类比赛。</li></ol><p>&#x3D;&#x3D;不禁感慨，短短 8 年，计算机视觉在图像分类领域取得了如此卓越的进步。&#x3D;&#x3D;</p><p><img src="/AI/image-20220818171819211-1661939503311123.png" alt="image-20220818171819211"></p><p>图片说明：上图展示的是计算机视觉中图像分类技术的发展。横坐标为时间，纵坐标为分类误差。</p><p>其中关键的时间结点是 2012 年 AlexNet 的横空出世开启了图像分类的新纪元。首次引入深度学习中的卷积神经网络。而在 2012 年以前还是采用传统的特征工程的方法人为的提取出图片不同的特征。而卷积神经网络是自动的提取出图片特征。</p><p>因为图像分类领域已经处于一个很高的水平，技术相对成熟，于是科学家们又转战到计算机视觉的另一个领域——目标检测。</p><p><img src="/AI/image-20220818172442170-1661939503311124.png" alt="image-20220818172442170"></p><p>图片说明：上图最上方的云梯图展示了目标检测技术的发展过程和重要时间点关键的技术。</p><p>可以初步划分为两个阶段：</p><ul><li><p>两阶段目标检测：在 YOLO 提出以前，属于两阶段的目标检测。所谓两阶段，是指目标检测分为两个阶段：1. 先从图像中提取出很多很多候选框；2. 再逐个分别分析每个候选框内的图像内容，最后将置信度高的候选框挑选出来，展示最终的目标检测结果。重要的典型算法如 R—CNN，第一次将 CNN 卷积神经网络用于目标检测里面。</p><p>两阶段目标检测的缺点：算法执行效率很慢，但精确率很高。</p></li><li><p>单阶段目标检测：例如 2016 年提出 YOLO 模型（重要时间结点），是单阶段目标检测方法，它不需要提出候选框，直接将图片输入即可得到目标检测结果。特点是算法执行效率非常快，模型运行速度很快。</p></li></ul><h2 id="第二课——安装openCV"><a href="#第二课——安装openCV" class="headerlink" title="第二课——安装openCV"></a>第二课——安装openCV</h2><ul><li>Step 1：下载 python 解释器，直接官网下载即可。安装成功提示如下图，配置好 python 环境变量后在 windows 的命令行窗口输入：python，显示安装的 python 解释器对应版本号即代表安装成功。</li></ul><p><img src="/AI/image-20220819225125424-1661939503311127.png" alt="image-20220819225125424"></p><ul><li><p>Step 2：pip 切换镜像源。</p><p><img src="/AI/image-20220819233744661-1661939503311125.png" alt="image-20220819233744661"></p><blockquote><ol><li><p>pip 类似一个全部基于 python 开发的 app 应用商场。</p></li><li><p>注意 pip <strong>不是 python 命令</strong>，是基于<strong>操作系统的命令</strong>，所以应该直接在<strong>命令行（cmd）输入</strong>对应指令而不要在 python 命令行<code>&gt;&gt;&gt;</code>输入。</p></li><li><p>切换镜像源可以加快应用文件的下载速度。相当于国内的某人已经帮你下好了，你直接从他那下，不用去到外网。</p></li></ol></blockquote><p>国内目前有很多镜像源，较好用的例如阿里云镜像站，清华大学镜像站等高校镜像站。</p><ul><li><p>将 pip 的<strong>下载源</strong>永久切换为<strong>阿里云的镜像站</strong></p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vim">pip config <span class="hljs-keyword">set</span> <span class="hljs-keyword">global</span>.<span class="hljs-built_in">index</span>-url https://mirrors.aliyun.<span class="hljs-keyword">com</span>/pypi/simple/<br></code></pre></td></tr></table></figure></li><li><p>将 pip 的<strong>下载源</strong>永久切换为<strong>清华的镜像站</strong></p><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gams">pip config <span class="hljs-keyword">set</span> global.index-url <span class="hljs-comment">https:</span>//<span class="hljs-comment">pypi.tuna.tsinghua.edu.cn</span>/simple/<br></code></pre></td></tr></table></figure></li></ul><p>补充：</p><p><img src="/AI/image-20220819234009147-1661939503311126.png" alt="image-20220819234009147"></p><p><img src="/AI/image-20220819234126710-1661939503311128.png" alt="image-20220819234126710"></p></li><li><p>Step 3：安装 python—opencv（最好在这一步之前切换一下pip安装文件的默认路径，一般默认安装在C盘，建议改在别的盘，具体操作直接百度即可。）</p><p>Windows <code>cmd</code> 命令行窗口直接输入下面语句即可安装。用阿里云的镜像源下载还是很快的。</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">pip <span class="hljs-keyword">install</span>  opencv-python<br></code></pre></td></tr></table></figure></li></ul><p>通过 <code>pip list</code> 命令查看，若有 <code>opencv-python   4.6.0.66</code> 信息则表示安装成功（版本号可能不同，出现有就行）。至此 opencv 安装完成！</p><hr><h1 id="深度学习硬件配置"><a href="#深度学习硬件配置" class="headerlink" title="深度学习硬件配置"></a>深度学习硬件配置</h1><h2 id="显卡"><a href="#显卡" class="headerlink" title="显卡"></a>显卡</h2><h1 id="Windows-深度学习环境搭建"><a href="#Windows-深度学习环境搭建" class="headerlink" title="Windows 深度学习环境搭建"></a>Windows 深度学习环境搭建</h1><p><strong>第一步：安装CUDA</strong></p><p>前言：CUDA（Compute Unified Device Architecture） 是 NVIDIA 推出的一种并行计算平台和编程模型。它通过利用图形处理器 (GPU) 的处理能力，可大幅提升计算性能。可以理解为厂家提供了一个平台方便用户调用GPU实现高效的并行能力。只有NVidia显卡才能使用CUDA。当然用户也可以不使用CUDA，直接面向显卡驱动接口也可以调用GPU，当然由于这种方案很不友好。所有NVIDIA推出了更加高效便捷的CUDA。(来源于网络)</p><ul><li><p>1）查看本机显卡驱动版本号，从而确定安装的 CUDA 版本号。（有两种方法，其中方法2更简单）</p><ul><li>方法1：桌面右击进入NVIDIA控制面板——&gt;点击左下角的系统信息——&gt;查看驱动版本号。具体步骤如下图所示，所以得到本机的驱动版本号为：511.79。</li></ul><img src="AI/image-20220828112522500-1661939559664143.png" alt="image-20220828112522500" style="zoom: 80%;" /><img src="AI/image-20220828112806636-1661939559664144.png" alt="image-20220828112806636"  /><ul><li><p>方法2：桌面右击进入NVIDIA控制面板——&gt;点击左下角的系统信息——&gt;组件，直接查看本机的CUDA支持的版本。可以看到本机的显卡支持CUDA 11.6版本，于是可以直接去CUDA官网下载CUDA11.6 版本的CUDA Toolkit 即可。</p><p><img src="/AI/image-20220828130610498-1661939559664145.png" alt="image-20220828130610498"></p></li></ul></li><li><p>2）浏览器直接搜索 CUDA，进入 CUDA 官网，下载对应版本的 CUDA 安装包。</p><p>比对下表（下表是在进入 CUDA 官网后找到 Release Notes 链接，然后点击进去下拉找到 Table3），因为上一步得知本机显卡驱动版本为511.79，因此选择 CUDA 11.6 Update 2 进行安装。</p><p><img src="/AI/image-20220828113641777-1661939559664146.png" alt="image-20220828113641777"></p></li><li><p>3）直接点击前面下载好的CUDA安装包进行安装即可。</p><p>选择自定义安装，修改安装位置，然后等待安装结束即可。安装后系统会自动添加环境变量。</p><p><img src="/AI/image-20220828132927367-1661939559664147.png" alt="image-20220828132927367"></p><p><img src="/AI/image-20220828135503321-1661939559664148.png" alt="image-20220828135503321"></p></li><li><p>4）查看是否CUDA安装成功。</p><ul><li><p>方法1：</p><p>Windows 命令行窗口输入：<code>nvcc -V</code>（注意：是大写的V），出现类似下面信息则表示安装成功。</p></li></ul><p><img src="/AI/image-20220828135715221-1661939559664149.png" alt="image-20220828135715221"></p><ul><li><p>方法2：</p><p>Windows 命令行窗口输入：<code>nividia-smi</code> (注意：nividia 和 -smi 之间没有空格)</p><p><img src="/AI/image-20220828141452704-1661939559664150.png" alt="image-20220828141452704"></p><p>可以看到本机上的显卡型号以及安装好的CUDA版本为11.6。</p></li></ul></li></ul><p><strong>第二步：安装 conda (通过安装Anaconda 或者 Miniconda 来间接获得 conda)</strong></p><p>Q1：为什么需要安装 conda？</p><p>A：运行不同的项目依赖的 pytorch 和 python 等版本不同，所以我们有安装不同版本的需求。<strong>conda 可以帮我们安装多个版本的软件包及其依赖关系，并在它们之间轻松切换</strong>。</p><p>Q2：怎么安装 conda？</p><p>A2：Anaconda，Miniconda 是包含了很多工具的集合，它们都包含了<strong>conda、Python包及其依赖项</strong>，安装它们就具备了conda 的环境。</p><p>Q3：Anaconda 和 Miniconda 的区别？</p><p>A3：Anaconda 含有的包等资源内容更丰富，Miniconda 可以理解为 Anaconda 的精简版。</p><p>这里选用安装 Miniconda，以下为安装步骤。</p>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
    </categories>
    
    
    <tags>
      
      <tag>学习笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
